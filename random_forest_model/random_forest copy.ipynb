{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59efefcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from skimage.feature import hog\n",
    "from skimage import feature\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.svm import SVC\n",
    "import joblib\n",
    "import json\n",
    "import random\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "\n",
    "import glob\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support, roc_curve, auc\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from torchvision.transforms import ToPILImage\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# importing malaria dataset class to map bounding boxes on one image\n",
    "# and skipping any null values with detection collate\n",
    "import sys\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(parent_dir)\n",
    "from malaria_dataset import MalariaDataset, detection_collate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01d51536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Path: ..\\dataset\\malaria\n",
      "Train Base Path: ..\\dataset\\malaria\\training_ds\n",
      "Test Base Path: ..\\dataset\\malaria\\testing_ds\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "root_path = os.path.join('..', 'dataset', 'malaria')\n",
    "train_base_path = os.path.join(root_path, 'training_ds')\n",
    "test_base_path = os.path.join(root_path, 'testing_ds')\n",
    "image_path = os.path.join(root_path, 'images')\n",
    "train_json_path = os.path.join(root_path, 'training.json')\n",
    "test_json_path = os.path.join(root_path, 'test.json')\n",
    "\n",
    "FEATURES_DIR = os.path.join(root_path, 'extracted_features')\n",
    "os.makedirs(FEATURES_DIR, exist_ok=True)\n",
    "\n",
    "image_sizes = [128]\n",
    "print(\"Root Path:\", root_path)\n",
    "print(\"Train Base Path:\", train_base_path)\n",
    "print(\"Test Base Path:\", test_base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333b4165",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "372e778f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================\n",
      "RUNNING EXPERIMENT\n",
      "Image Size: 128x128 | Feature Extractor: HIST\n",
      "=========================\n",
      "Loading pre-trained model from: .\\trained_models\\128_HIST_rf_model.pkl\n",
      "\n",
      "--- Evaluation Results ---\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     difficult       0.17      0.06      0.09        16\n",
      "    gametocyte       0.00      0.00      0.00        14\n",
      "     leukocyte       1.00      0.81      0.89        21\n",
      "red_blood_cell       0.96      1.00      0.98      6869\n",
      "          ring       1.00      0.01      0.01       173\n",
      "      schizont       0.00      0.00      0.00        12\n",
      "   trophozoite       0.77      0.32      0.45       168\n",
      "\n",
      "      accuracy                           0.95      7273\n",
      "     macro avg       0.56      0.31      0.35      7273\n",
      "  weighted avg       0.95      0.95      0.94      7273\n",
      "\n",
      "\n",
      "=========================\n",
      "RUNNING EXPERIMENT\n",
      "Image Size: 128x128 | Feature Extractor: HOG\n",
      "=========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shera\\miniconda3\\envs\\fyp2\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\shera\\miniconda3\\envs\\fyp2\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\shera\\miniconda3\\envs\\fyp2\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\shera\\miniconda3\\envs\\fyp2\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\shera\\miniconda3\\envs\\fyp2\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\shera\\miniconda3\\envs\\fyp2\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained model from: .\\trained_models\\128_HOG_rf_model.pkl\n",
      "\n",
      "--- Evaluation Results ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shera\\miniconda3\\envs\\fyp2\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\shera\\miniconda3\\envs\\fyp2\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\shera\\miniconda3\\envs\\fyp2\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\shera\\miniconda3\\envs\\fyp2\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\shera\\miniconda3\\envs\\fyp2\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\shera\\miniconda3\\envs\\fyp2\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "     difficult       0.00      0.00      0.00        16\n",
      "    gametocyte       0.00      0.00      0.00        14\n",
      "     leukocyte       0.82      0.43      0.56        21\n",
      "red_blood_cell       0.95      1.00      0.97      6869\n",
      "          ring       0.00      0.00      0.00       173\n",
      "      schizont       0.00      0.00      0.00        12\n",
      "   trophozoite       0.58      0.11      0.19       168\n",
      "\n",
      "      accuracy                           0.95      7273\n",
      "     macro avg       0.33      0.22      0.25      7273\n",
      "  weighted avg       0.91      0.95      0.92      7273\n",
      "\n",
      "\n",
      "=========================\n",
      "RUNNING EXPERIMENT\n",
      "Image Size: 128x128 | Feature Extractor: LBP\n",
      "=========================\n",
      "Loading pre-trained model from: .\\trained_models\\128_LBP_rf_model.pkl\n",
      "\n",
      "--- Evaluation Results ---\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     difficult       0.00      0.06      0.01        16\n",
      "    gametocyte       0.04      0.14      0.07        14\n",
      "     leukocyte       0.38      0.38      0.38        21\n",
      "red_blood_cell       0.98      0.91      0.95      6869\n",
      "          ring       0.43      0.06      0.10       173\n",
      "      schizont       0.01      0.08      0.02        12\n",
      "   trophozoite       0.21      0.54      0.30       168\n",
      "\n",
      "      accuracy                           0.88      7273\n",
      "     macro avg       0.29      0.31      0.26      7273\n",
      "  weighted avg       0.95      0.88      0.90      7273\n",
      "\n",
      "\n",
      "==============================\n",
      "FINAL EXPERIMENT SUMMARY\n",
      "==============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_size</th>\n",
       "      <th>feature_extractor</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score_weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>HIST</td>\n",
       "      <td>0.953664</td>\n",
       "      <td>0.936408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128</td>\n",
       "      <td>HOG</td>\n",
       "      <td>0.946240</td>\n",
       "      <td>0.924316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128</td>\n",
       "      <td>LBP</td>\n",
       "      <td>0.875430</td>\n",
       "      <td>0.903663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_size feature_extractor  accuracy  f1_score_weighted\n",
       "0        128              HIST  0.953664           0.936408\n",
       "1        128               HOG  0.946240           0.924316\n",
       "2        128               LBP  0.875430           0.903663"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary saved to model_experiment_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# --- Create a directory to store the trained models ---\n",
    "MODELS_DIR = os.path.join('.', 'trained_models')\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "\n",
    "experiment_results = []\n",
    "feature_files = glob.glob(os.path.join(FEATURES_DIR, \"*.pkl\"))\n",
    "\n",
    "if not feature_files:\n",
    "    print(\"ERROR: No feature files found!\")\n",
    "    print(f\"Please run the Feature Extraction cell first to create .pkl files in: {FEATURES_DIR}\")\n",
    "\n",
    "# --- Main Training Loop ---\n",
    "for file_path in feature_files:\n",
    "    filename = os.path.basename(file_path)\n",
    "    # Correctly unpack filename assuming format \"size_extractorName_features.pkl\"\n",
    "    size, extractor_name, _ = filename.split('_', 2)\n",
    "    \n",
    "    print(f\"\\n{'='*25}\")\n",
    "    print(f\"RUNNING EXPERIMENT\")\n",
    "    print(f\"Image Size: {size}x{size} | Feature Extractor: {extractor_name}\")\n",
    "    print(f\"{'='*25}\")\n",
    "    \n",
    "    # --- 1. Load Pre-computed Feature Data ---\n",
    "    data = joblib.load(file_path)\n",
    "    X_train, y_train = data['X_train'], data['y_train']\n",
    "    X_test, y_test = data['X_test'], data['y_test']\n",
    "    le = data['label_encoder']\n",
    "    \n",
    "    # --- 2. Build, Train, or Load the Pipeline ---\n",
    "    # MODIFIED: Changed model name in path to 'rf_model' for clarity\n",
    "    model_path = os.path.join(MODELS_DIR, f\"{size}_{extractor_name}_rf_model.pkl\")\n",
    "\n",
    "    # --- Check if the model is already trained ---\n",
    "    if os.path.exists(model_path):\n",
    "        print(f\"Loading pre-trained model from: {model_path}\")\n",
    "        pipeline = joblib.load(model_path)\n",
    "    else:\n",
    "        # If model not found, define the pipeline and train it\n",
    "        print(\"Pre-trained model not found. Training a new model...\")\n",
    "        \n",
    "        # --- MODIFICATION START ---\n",
    "        # Replaced the SVM pipeline with a RandomForest pipeline\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),  # Scaling is less critical for RF but kept for consistency\n",
    "            ('smote', SMOTE(random_state=42)),\n",
    "            ('rf', RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)) # Using RandomForest\n",
    "        ])\n",
    "        # --- MODIFICATION END ---\n",
    "        \n",
    "        pipeline.fit(X_train, y_train) # This is the training line\n",
    "        \n",
    "        # --- Save the newly trained pipeline ---\n",
    "        print(f\"Saving trained model to: {model_path}\")\n",
    "        joblib.dump(pipeline, model_path)\n",
    "\n",
    "    # --- 3. Evaluation ---\n",
    "    print(\"\\n--- Evaluation Results ---\")\n",
    "    predictions = pipeline.predict(X_test)\n",
    "    report = classification_report(y_test, predictions, target_names=le.classes_, output_dict=True)\n",
    "    print(classification_report(y_test, predictions, target_names=le.classes_))\n",
    "\n",
    "    # --- 4. Store Results for Final Summary ---\n",
    "    experiment_results.append({\n",
    "        'image_size': size,\n",
    "        'feature_extractor': extractor_name,\n",
    "        'accuracy': report['accuracy'],\n",
    "        'f1_score_weighted': report['weighted avg']['f1-score']\n",
    "    })\n",
    "\n",
    "# --- 5. Display Final Summary Table ---\n",
    "if experiment_results:\n",
    "    print(f\"\\n{'='*30}\")\n",
    "    print(\"FINAL EXPERIMENT SUMMARY\")\n",
    "    print(f\"{'='*30}\")\n",
    "    results_df = pd.DataFrame(experiment_results)\n",
    "    results_df = results_df.sort_values(by='f1_score_weighted', ascending=False)\n",
    "    display(results_df)\n",
    "    \n",
    "    summary_path = 'model_experiment_summary.csv'\n",
    "    results_df.to_csv(summary_path, index=False)\n",
    "    print(f\"\\nSummary saved to {summary_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0da45d5",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a2f8948",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR    = os.path.join('.', 'detections')\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# If your training labels used these common names, we'll auto-pick the positive label.\n",
    "MALARIA_POSITIVE_ALIASES = {'ring', 'trophozoite', 'schizont', 'gametocyte'}\n",
    "COLOR_HDR_BG = (32, 32, 32)\n",
    "COLOR_HDR_TXT = (255, 255, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b46e256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# ENHANCED MALARIA DETECTOR\n",
    "# =========================\n",
    "# Works with your saved RandomForest pipeline:\n",
    "#   trained_models/{size}_{extractor}_rf_model.pkl\n",
    "# and your features file:\n",
    "#   ../dataset/malaria/extracted_features/{size}_{extractor}_features.pkl\n",
    "#\n",
    "# Output:\n",
    "#  - detections/<img>__detections.png         (boxes)\n",
    "#  - detections/vis/<img>__gt_vs_pred.png     (header + boxes)\n",
    "#  - detections/<img>__heatmap.png            (prob heatmap overlay)\n",
    "#  - detections/vis/<img>__topK.png           (mosaic of top windows)\n",
    "#  - detections/vis/report.csv                (per-image summary)\n",
    "\n",
    "import os, re, glob, math, json, warnings\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import cv2\n",
    "import joblib\n",
    "\n",
    "# Make sure these imports exist so joblib can unpickle your pipeline\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "# -------------------------\n",
    "# PATHS (kept consistent with your notebook)\n",
    "# -------------------------\n",
    "ROOT_PATH       = os.path.join('..', 'dataset', 'malaria')\n",
    "TRAIN_DIR       = os.path.join(ROOT_PATH, 'training_ds')\n",
    "TEST_DIR        = os.path.join(ROOT_PATH, 'testing_ds')\n",
    "FEATURES_DIR    = os.path.join(ROOT_PATH, 'extracted_features')\n",
    "MODELS_DIR      = os.path.join('.', 'trained_models')\n",
    "OUTPUT_DIR      = os.path.join('.', 'detections')\n",
    "VIS_DIR         = os.path.join(OUTPUT_DIR, 'vis')\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(VIS_DIR, exist_ok=True)\n",
    "\n",
    "# For GT inference if you don't have JSON: parent folder name\n",
    "POSITIVE_ALIASES = {'parasitized', 'infected', 'positive', 'malaria', 'parasite', 'malaria_cell'}\n",
    "\n",
    "# -------------------------\n",
    "# Small drawing helpers\n",
    "# -------------------------\n",
    "def _put_text(img, text, org, scale=0.6, color=(255,255,255), thickness=1, bg=(0,0,0)):\n",
    "    pad = 2\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    (tw, th), baseline = cv2.getTextSize(text, font, scale, thickness)\n",
    "    x, y = org\n",
    "    cv2.rectangle(img, (x, y - th - 2*pad), (x + tw + 2*pad, y + baseline), bg, -1)\n",
    "    cv2.putText(img, text, (x + pad, y - pad), font, scale, color, thickness, cv2.LINE_AA)\n",
    "\n",
    "def _draw_header(img_bgr, left_text, scale=0.7):\n",
    "    out = img_bgr.copy()\n",
    "    H, W = out.shape[:2]\n",
    "    bar_h = max(30, int(30 * scale))\n",
    "    cv2.rectangle(out, (0, 0), (W, bar_h + 10), (32, 32, 32), -1)\n",
    "    _put_text(out, left_text, (10, bar_h), scale=scale, color=(255,255,255), bg=(32,32,32))\n",
    "    return out\n",
    "\n",
    "# -------------------------\n",
    "# Non-Max Suppression\n",
    "# -------------------------\n",
    "def nms(boxes, scores, iou_threshold=0.3, top_k=None):\n",
    "    if not boxes:\n",
    "        return []\n",
    "    boxes = np.asarray(boxes, dtype=float)\n",
    "    scores = np.asarray(scores, dtype=float)\n",
    "    x1, y1, x2, y2 = boxes.T\n",
    "    areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    order = scores.argsort()[::-1]\n",
    "    keep = []\n",
    "    while order.size > 0:\n",
    "        i = order[0]\n",
    "        keep.append(i)\n",
    "        if top_k is not None and len(keep) >= top_k:\n",
    "            break\n",
    "        xx1 = np.maximum(x1[i], x1[order[1:]])\n",
    "        yy1 = np.maximum(y1[i], y1[order[1:]])\n",
    "        xx2 = np.minimum(x2[i], x2[order[1:]])\n",
    "        yy2 = np.minimum(y2[i], y2[order[1:]])\n",
    "        w = np.maximum(0.0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0.0, yy2 - yy1 + 1)\n",
    "        inter = w * h\n",
    "        iou = inter / (areas[i] + areas[order[1:]] - inter + 1e-9)\n",
    "        inds = np.where(iou <= iou_threshold)[0]\n",
    "        order = order[inds + 1]\n",
    "    return keep\n",
    "\n",
    "# -------------------------\n",
    "# Pyramid + sliding window (handles upsampling tiny images)\n",
    "# -------------------------\n",
    "def image_pyramid(img, scale=1.25, min_size=(64,64), window_size=(128,128)):\n",
    "    H0, W0 = img.shape[:2]\n",
    "    # Upsample if the original is smaller than the window\n",
    "    scale_up = max(window_size[0] / W0, window_size[1] / H0, 1.0)\n",
    "    if scale_up > 1.0:\n",
    "        new_w = int(round(W0 * scale_up))\n",
    "        new_h = int(round(H0 * scale_up))\n",
    "        img_up = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_LINEAR)\n",
    "        yield scale_up, img_up   # note: factor here is how many times larger than original\n",
    "        current = img_up.copy()\n",
    "        current_scale = scale_up\n",
    "    else:\n",
    "        yield 1.0, img.copy()\n",
    "        current = img.copy()\n",
    "        current_scale = 1.0\n",
    "\n",
    "    while True:\n",
    "        new_w = int(current.shape[1] / scale)\n",
    "        new_h = int(current.shape[0] / scale)\n",
    "        if new_w < min_size[0] or new_h < min_size[1]:\n",
    "            break\n",
    "        current = cv2.resize(current, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "        current_scale /= scale\n",
    "        yield current_scale, current\n",
    "\n",
    "def sliding_window(image, window_size, step=16):\n",
    "    H, W = image.shape[:2]\n",
    "    wW, wH = window_size\n",
    "    if W < wW or H < wH:\n",
    "        return\n",
    "    for y in range(0, H - wH + 1, step):\n",
    "        for x in range(0, W - wW + 1, step):\n",
    "            patch = image[y:y+wH, x:x+wW]\n",
    "            yield x, y, patch\n",
    "\n",
    "# -------------------------\n",
    "# Auto-configure HOG to match your trained pipeline\n",
    "# -------------------------\n",
    "def get_expected_feature_len(pipeline):\n",
    "    exp = None\n",
    "    if 'scaler' in pipeline.named_steps and hasattr(pipeline.named_steps['scaler'], 'n_features_in_'):\n",
    "        exp = int(pipeline.named_steps['scaler'].n_features_in_)\n",
    "    elif 'rf' in pipeline.named_steps and hasattr(pipeline.named_steps['rf'], 'n_features_in_'):\n",
    "        exp = int(pipeline.named_steps['rf'].n_features_in_)\n",
    "    return exp\n",
    "\n",
    "def hog_feature_len(size, orientations, ppc, cpb):\n",
    "    # compute HOG length by running once on zeros\n",
    "    dummy = np.zeros((size, size), dtype=np.float32)\n",
    "    feats = hog(dummy,\n",
    "                orientations=orientations,\n",
    "                pixels_per_cell=ppc,\n",
    "                cells_per_block=cpb,\n",
    "                block_norm='L2-Hys',\n",
    "                transform_sqrt=False,\n",
    "                feature_vector=True)\n",
    "    return feats.size\n",
    "\n",
    "def auto_configure_hog(model_size, expected_len):\n",
    "    # Try a few common combos; add more if you trained differently\n",
    "    candidates = [\n",
    "        dict(orientations=9, pixels_per_cell=(16,16), cells_per_block=(2,2)),\n",
    "        dict(orientations=9, pixels_per_cell=(8,8),   cells_per_block=(2,2)),\n",
    "        dict(orientations=8, pixels_per_cell=(16,16), cells_per_block=(2,2)),\n",
    "        dict(orientations=9, pixels_per_cell=(32,32), cells_per_block=(2,2)),\n",
    "    ]\n",
    "    for cand in candidates:\n",
    "        if hog_feature_len(model_size, cand['orientations'], cand['pixels_per_cell'], cand['cells_per_block']) == expected_len:\n",
    "            return cand\n",
    "    # Fallback: stick with the classic 1764-dim (for 128, 9, 16,2,2) if expected is close:\n",
    "    default = dict(orientations=9, pixels_per_cell=(16,16), cells_per_block=(2,2))\n",
    "    warnings.warn(f\"[HOG] Could not auto-match expected feature length {expected_len}. Using default {default}.\")\n",
    "    return default\n",
    "\n",
    "# -------------------------\n",
    "# Load model + label encoder\n",
    "# -------------------------\n",
    "def load_pipeline_and_label_encoder(model_size, extractor_name):\n",
    "    size_str = str(int(model_size))\n",
    "    model_path = os.path.join(MODELS_DIR, f\"{size_str}_{extractor_name}_rf_model.pkl\")\n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"Model not found: {model_path}\")\n",
    "\n",
    "    pipeline = joblib.load(model_path)\n",
    "\n",
    "    # Try to get label encoder from features file (preferred)\n",
    "    feats_path = os.path.join(FEATURES_DIR, f\"{size_str}_{extractor_name}_features.pkl\")\n",
    "    le = None\n",
    "    if os.path.exists(feats_path):\n",
    "        data = joblib.load(feats_path)\n",
    "        le = data.get('label_encoder', None)\n",
    "\n",
    "    # Positive class inference (requires label names ideally)\n",
    "    if le is not None:\n",
    "        pos_label_name = None\n",
    "        for name in le.classes_:\n",
    "            if name.strip().lower() in POSITIVE_ALIASES or name in {'Parasitized', 'Infected'}:\n",
    "                pos_label_name = name\n",
    "                break\n",
    "        if pos_label_name is None and len(le.classes_) >= 2:\n",
    "            pos_label_name = le.classes_[0]\n",
    "    else:\n",
    "        pos_label_name = 'Parasitized'  # sensible default for NIH malaria\n",
    "\n",
    "    # Map pos label to the rf.classes_ index\n",
    "    rf = pipeline.named_steps.get('rf', None)\n",
    "    if rf is None:\n",
    "        raise RuntimeError(\"Pipeline does not have a step named 'rf'.\")\n",
    "    if le is not None:\n",
    "        encoded_pos = le.transform([pos_label_name])[0]\n",
    "    else:\n",
    "        # Fallback guess if we lack a LabelEncoder\n",
    "        encoded_pos = 1 if hasattr(rf, 'classes_') and 1 in rf.classes_ else rf.classes_[0]\n",
    "\n",
    "    rf_class_order = list(rf.classes_)\n",
    "    if encoded_pos not in rf_class_order:\n",
    "        raise RuntimeError(f\"Positive encoded label {encoded_pos} not in rf.classes_={rf_class_order}\")\n",
    "    pos_index = rf_class_order.index(encoded_pos)\n",
    "\n",
    "    # Configure HOG to match expected feature length\n",
    "    expected_len = get_expected_feature_len(pipeline)\n",
    "    if expected_len is None:\n",
    "        expected_len = 1764  # common for 128/HOG(16,2,2)\n",
    "    hog_cfg = auto_configure_hog(int(model_size), expected_len)\n",
    "\n",
    "    return pipeline, le, pos_label_name, pos_index, hog_cfg\n",
    "\n",
    "# -------------------------\n",
    "# Feature extraction (HOG/LBP; HOG is default for your RF)\n",
    "# -------------------------\n",
    "def extract_features(patch_bgr, size, extractor_name, hog_cfg):\n",
    "    if patch_bgr.shape[:2] != (size, size):\n",
    "        patch_bgr = cv2.resize(patch_bgr, (size, size), interpolation=cv2.INTER_AREA)\n",
    "    gray = cv2.cvtColor(patch_bgr, cv2.COLOR_BGR2GRAY).astype(np.float32)\n",
    "    gray /= 255.0\n",
    "\n",
    "    if extractor_name.lower() == 'hog':\n",
    "        feats = hog(gray,\n",
    "                    orientations=hog_cfg['orientations'],\n",
    "                    pixels_per_cell=hog_cfg['pixels_per_cell'],\n",
    "                    cells_per_block=hog_cfg['cells_per_block'],\n",
    "                    block_norm='L2-Hys',\n",
    "                    transform_sqrt=False,\n",
    "                    feature_vector=True)\n",
    "        return feats.astype(np.float32)\n",
    "\n",
    "    elif extractor_name.lower() == 'lbp':\n",
    "        P, R = 8, 1\n",
    "        lbp = local_binary_pattern(gray, P=P, R=R, method='uniform')\n",
    "        hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, P+3), range=(0, P+2), density=True)\n",
    "        return hist.astype(np.float32)\n",
    "\n",
    "    elif extractor_name.lower() in {'hog_lbp', 'lbp_hog'}:\n",
    "        feats_hog = hog(gray,\n",
    "                        orientations=hog_cfg['orientations'],\n",
    "                        pixels_per_cell=hog_cfg['pixels_per_cell'],\n",
    "                        cells_per_block=hog_cfg['cells_per_block'],\n",
    "                        block_norm='L2-Hys',\n",
    "                        transform_sqrt=False,\n",
    "                        feature_vector=True)\n",
    "        P, R = 8, 1\n",
    "        lbp = local_binary_pattern(gray, P=P, R=R, method='uniform')\n",
    "        hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, P+3), range=(0, P+2), density=True)\n",
    "        return np.hstack([feats_hog.astype(np.float32), hist.astype(np.float32)])\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown extractor '{extractor_name}'.\")\n",
    "\n",
    "# -------------------------\n",
    "# Core detection\n",
    "# -------------------------\n",
    "def detect_image(\n",
    "    image_path,\n",
    "    model_size=128,\n",
    "    extractor_name='hog',\n",
    "    step=None,                 # if None -> model_size//4\n",
    "    pyramid_scale=1.25,\n",
    "    prob_threshold=0.80,\n",
    "    nms_iou=0.25,\n",
    "    top_k=None\n",
    "):\n",
    "    pipeline, le, pos_label_name, pos_index, hog_cfg = load_pipeline_and_label_encoder(model_size, extractor_name)\n",
    "\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"Could not read image: {image_path}\")\n",
    "    H0, W0 = img.shape[:2]\n",
    "\n",
    "    win_size = (int(model_size), int(model_size))\n",
    "    if step is None:\n",
    "        step = max(8, int(model_size // 4))\n",
    "\n",
    "    # Soft heat accumulation at window centers\n",
    "    prob_accum = np.zeros((H0, W0), dtype=np.float32)\n",
    "    prob_count = np.zeros((H0, W0), dtype=np.float32)\n",
    "\n",
    "    boxes, scores = [], []\n",
    "    rf = pipeline.named_steps['rf']\n",
    "\n",
    "    # scan pyramid\n",
    "    for scale_factor, im_scaled in image_pyramid(img, scale=pyramid_scale, min_size=win_size, window_size=win_size):\n",
    "        for x, y, patch in sliding_window(im_scaled, window_size=win_size, step=step):\n",
    "            feats = extract_features(patch, size=model_size, extractor_name=extractor_name, hog_cfg=hog_cfg).reshape(1, -1)\n",
    "            proba = pipeline.predict_proba(feats)[0]  # RandomForest supports this\n",
    "            p_pos = float(proba[pos_index])\n",
    "\n",
    "            # record box if above threshold\n",
    "            if p_pos >= prob_threshold:\n",
    "                x1 = int(x / scale_factor)\n",
    "                y1 = int(y / scale_factor)\n",
    "                x2 = int((x + win_size[0]) / scale_factor)\n",
    "                y2 = int((y + win_size[1]) / scale_factor)\n",
    "                # clamp\n",
    "                x1 = max(0, min(W0-1, x1)); x2 = max(0, min(W0-1, x2))\n",
    "                y1 = max(0, min(H0-1, y1)); y2 = max(0, min(H0-1, y2))\n",
    "\n",
    "                boxes.append([x1, y1, x2, y2])\n",
    "                scores.append(p_pos)\n",
    "\n",
    "            # heatmap accumulation\n",
    "            cx = int((x + win_size[0] / 2) / scale_factor)\n",
    "            cy = int((y + win_size[1] / 2) / scale_factor)\n",
    "            if 0 <= cx < W0 and 0 <= cy < H0:\n",
    "                prob_accum[cy, cx] += p_pos\n",
    "                prob_count[cy, cx] += 1.0\n",
    "\n",
    "    # average heat\n",
    "    with np.errstate(invalid='ignore'):\n",
    "        heatmap = np.where(prob_count > 0, prob_accum / np.maximum(prob_count, 1e-6), 0.0)\n",
    "\n",
    "    # NMS\n",
    "    keep = nms(boxes, scores, iou_threshold=nms_iou, top_k=top_k)\n",
    "    boxes_nms = [boxes[i] for i in keep]\n",
    "    scores_nms = [scores[i] for i in keep]\n",
    "\n",
    "    has_malaria = len(boxes_nms) > 0\n",
    "\n",
    "    # Save base overlays\n",
    "    base = Path(image_path).stem\n",
    "    overlay_path = os.path.join(OUTPUT_DIR, f\"{base}__detections.png\")\n",
    "    heatmap_path = os.path.join(OUTPUT_DIR, f\"{base}__heatmap.png\")\n",
    "\n",
    "    vis = img.copy()\n",
    "    for (x1, y1, x2, y2), s in zip(boxes_nms, scores_nms):\n",
    "        cv2.rectangle(vis, (x1, y1), (x2, y2), (0,255,0), 2)\n",
    "        _put_text(vis, f\"{pos_label_name} {s:.2f}\", (x1, max(0, y1-5)), scale=0.6, color=(0,0,0), bg=(0,255,0))\n",
    "    cv2.imwrite(overlay_path, vis)\n",
    "\n",
    "    hm_norm = (heatmap / (heatmap.max() + 1e-6) * 255.0).astype(np.uint8)\n",
    "    hm_color = cv2.applyColorMap(hm_norm, cv2.COLORMAP_JET)\n",
    "    hm_overlay = cv2.addWeighted(img, 0.6, hm_color, 0.4, 0)\n",
    "    cv2.imwrite(heatmap_path, hm_overlay)\n",
    "\n",
    "    return {\n",
    "        \"has_malaria\": bool(has_malaria),\n",
    "        \"positive_label\": pos_label_name,\n",
    "        \"boxes\": boxes_nms,\n",
    "        \"scores\": scores_nms,\n",
    "        \"overlay_png\": overlay_path,\n",
    "        \"heatmap_png\": heatmap_path\n",
    "    }\n",
    "\n",
    "# -------------------------\n",
    "# Visual: GT vs Pred header + top-k windows mosaic\n",
    "# -------------------------\n",
    "def infer_gt_from_parent(img_path):\n",
    "    parent = Path(img_path).parent.name.strip().lower()\n",
    "    is_pos = any(alias in parent for alias in POSITIVE_ALIASES)\n",
    "    return \"Positive\" if is_pos else \"Negative\"\n",
    "\n",
    "def save_gt_vs_pred_banner(image_path, detection_dict, out_dir=VIS_DIR):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    overlay = cv2.imread(detection_dict['overlay_png'])\n",
    "    if overlay is None:\n",
    "        overlay = cv2.imread(image_path)\n",
    "    gt_label   = infer_gt_from_parent(image_path)\n",
    "    pred_label = \"Positive\" if detection_dict['has_malaria'] else \"Negative\"\n",
    "    header = f\"GT: {gt_label}   |   Pred: {pred_label}   |   {detection_dict['positive_label']} windows: {len(detection_dict['boxes'])}\"\n",
    "    scale = max(0.6, min(overlay.shape[0], overlay.shape[1]) / 900.0)\n",
    "    out = _draw_header(overlay, header, scale=scale)\n",
    "    out_path = os.path.join(out_dir, f\"{Path(image_path).stem}__gt_vs_pred.png\")\n",
    "    cv2.imwrite(out_path, out)\n",
    "    return out_path, gt_label, pred_label\n",
    "\n",
    "def save_topk_mosaic(image_path, boxes, scores, k=6, out_dir=VIS_DIR):\n",
    "    if not boxes:\n",
    "        return None\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    img = cv2.imread(image_path)\n",
    "    ord_idx = np.argsort(-np.array(scores))[:k]\n",
    "    tiles = []\n",
    "    for i in ord_idx:\n",
    "        x1,y1,x2,y2 = [int(v) for v in boxes[i]]\n",
    "        crop = img[max(0,y1):max(0,y2), max(0,x1):max(0,x2)].copy()\n",
    "        if crop.size == 0:\n",
    "            continue\n",
    "        # add a mini banner on each crop\n",
    "        _put_text(crop, f\"{scores[i]:.2f}\", (5, 20), scale=0.6, bg=(0,0,0))\n",
    "        tiles.append(cv2.resize(crop, (128,128)))\n",
    "    if not tiles:\n",
    "        return None\n",
    "    # make a simple grid\n",
    "    rows = math.ceil(len(tiles)/3)\n",
    "    while len(tiles) < rows*3:\n",
    "        tiles.append(np.zeros_like(tiles[0]))\n",
    "    grid = []\n",
    "    for r in range(rows):\n",
    "        row = cv2.hconcat(tiles[r*3:(r+1)*3])\n",
    "        grid.append(row)\n",
    "    mosaic = cv2.vconcat(grid)\n",
    "    out_path = os.path.join(out_dir, f\"{Path(image_path).stem}__topK.png\")\n",
    "    cv2.imwrite(out_path, mosaic)\n",
    "    return out_path\n",
    "\n",
    "# -------------------------\n",
    "# High-level helpers\n",
    "# -------------------------\n",
    "def predict_and_visualize(\n",
    "    image_path,\n",
    "    model_size=128,\n",
    "    extractor_name='hog',\n",
    "    step=None,\n",
    "    pyramid_scale=1.25,\n",
    "    prob_threshold=0.80,\n",
    "    nms_iou=0.25\n",
    "):\n",
    "    det = detect_image(\n",
    "        image_path=image_path,\n",
    "        model_size=model_size,\n",
    "        extractor_name=extractor_name,\n",
    "        step=step,\n",
    "        pyramid_scale=pyramid_scale,\n",
    "        prob_threshold=prob_threshold,\n",
    "        nms_iou=nms_iou\n",
    "    )\n",
    "    banner_path, gt_label, pred_label = save_gt_vs_pred_banner(image_path, det, out_dir=VIS_DIR)\n",
    "    topk_path = save_topk_mosaic(image_path, det['boxes'], det['scores'], k=6, out_dir=VIS_DIR)\n",
    "    return {\n",
    "        \"image\": image_path,\n",
    "        \"gt\": gt_label,\n",
    "        \"pred\": pred_label,\n",
    "        \"num_windows\": len(det['boxes']),\n",
    "        \"overlay\": det['overlay_png'],\n",
    "        \"banner\": banner_path,\n",
    "        \"heatmap\": det['heatmap_png'],\n",
    "        \"topk\": topk_path\n",
    "    }\n",
    "\n",
    "def run_on_path(\n",
    "    path,                          # file or directory\n",
    "    model_size=128,\n",
    "    extractor_name='hog',\n",
    "    prob_threshold=0.80,\n",
    "    nms_iou=0.25,\n",
    "    pyramid_scale=1.25,\n",
    "    step=None,\n",
    "    exts=('.png','.jpg','.jpeg','.tif','.bmp')\n",
    "):\n",
    "    paths = []\n",
    "    p = Path(path)\n",
    "    if p.is_dir():\n",
    "        for ext in exts:\n",
    "            paths.extend(glob.glob(str(p / f\"*{ext}\")))\n",
    "            # also walk immediate subfolders (e.g., Parasitized/ *.png)\n",
    "            for sub in p.iterdir():\n",
    "                if sub.is_dir():\n",
    "                    paths.extend(glob.glob(str(sub / f\"*{ext}\")))\n",
    "    else:\n",
    "        if p.suffix.lower() in exts and p.exists():\n",
    "            paths = [str(p)]\n",
    "    if not paths:\n",
    "        raise FileNotFoundError(f\"No images found under: {path}\")\n",
    "\n",
    "    rows = []\n",
    "    for i, img_path in enumerate(sorted(paths)):\n",
    "        try:\n",
    "            res = predict_and_visualize(\n",
    "                image_path=img_path,\n",
    "                model_size=model_size,\n",
    "                extractor_name=extractor_name,\n",
    "                step=step,\n",
    "                pyramid_scale=pyramid_scale,\n",
    "                prob_threshold=prob_threshold,\n",
    "                nms_iou=nms_iou\n",
    "            )\n",
    "            rows.append(res)\n",
    "            print(f\"[{i+1}/{len(paths)}] {Path(img_path).name}: GT={res['gt']} Pred={res['pred']} windows={res['num_windows']}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] {img_path}: {e}\")\n",
    "\n",
    "    # CSV summary\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame(rows)\n",
    "    csv_path = os.path.join(VIS_DIR, \"report.csv\")\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"\\nSaved {len(rows)} results. Report: {csv_path}\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0aad0aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SIZE = 128\n",
    "EXTRACTOR  = 'hog'\n",
    "\n",
    "some_image = r\"C:\\Users\\shera\\Desktop\\fyp\\fyp\\dataset\\malaria\\images\\fed6ba05-36a5-45dc-a4e1-9baa7de2c622.png\"\n",
    "\n",
    "\n",
    "def predict_and_visualize_safe(img_or_list, **kwargs):\n",
    "    if isinstance(img_or_list, (list, tuple)):\n",
    "        if not img_or_list:\n",
    "            raise FileNotFoundError(\"Empty list of images.\")\n",
    "        img_path = img_or_list[0]\n",
    "    else:\n",
    "        img_path = img_or_list\n",
    "    return predict_and_visualize(image_path=img_path, **kwargs)\n",
    "\n",
    "# usage:\n",
    "res = predict_and_visualize_safe(\n",
    "    some_image,  # works whether this is a str path or a list from glob\n",
    "    model_size=MODEL_SIZE,\n",
    "    extractor_name=EXTRACTOR,\n",
    "    step=32,\n",
    "    pyramid_scale=1.25,\n",
    "    prob_threshold=0.80,\n",
    "    nms_iou=0.25\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
