{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a2b3c4d",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Configuration\n",
    "This section imports all necessary libraries and defines robust, absolute paths to our data and model directories. Using absolute paths is a best practice that prevents errors when running code from different locations or using background workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed360cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torchvision import transforms\n",
    "from torchvision.models import efficientnet_b2\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# --- 1. Robust Path Definitions (Best Practice) ---\n",
    "# Get the absolute path to the directory this notebook is in\n",
    "notebook_dir = os.path.abspath('')\n",
    "# Go UP one level to get the main project's base directory\n",
    "base_dir = os.path.dirname(notebook_dir)\n",
    "\n",
    "print(f\"Project base directory determined as: {base_dir}\")\n",
    "\n",
    "# Build all other paths from this absolute base_dir\n",
    "root_path = os.path.join(base_dir, 'dataset', 'malaria')\n",
    "train_json_path = os.path.join(root_path, 'training.json')\n",
    "test_json_path = os.path.join(root_path, 'test.json')\n",
    "models_dir = os.path.join(base_dir, 'effecientnetb2_model', 'efficientnet_models')\n",
    "image_path = os.path.join(root_path, 'images')\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Train JSON: {train_json_path}\")\n",
    "print(f\"Test JSON:  {test_json_path}\")\n",
    "print(f\"Images:     {image_path}\")\n",
    "print(f\"Models Dir: {models_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3c4d5e",
   "metadata": {},
   "source": [
    "## Step 2: Model and Dataset Definitions\n",
    "Here we define the core components: the `MalariaDataset` class to load our specific JSON format, the `EfficientNetDetector` model, and our custom loss functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "class_definitions",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MalariaDataset(Dataset):\n",
    "    def __init__(self, json_path, image_root, transform=None, category_map=None):\n",
    "        with open(json_path, 'r') as f:\n",
    "            self.entries = json.load(f)\n",
    "        self.image_root = image_root\n",
    "        self.transform = transform\n",
    "\n",
    "        if category_map is None:\n",
    "            all_categories = set()\n",
    "            for item in self.entries:\n",
    "                for obj in item['objects']:\n",
    "                    all_categories.add(obj['category'])\n",
    "            self.category_map = {cat: idx for idx, cat in enumerate(sorted(list(all_categories)))}\n",
    "        else:\n",
    "            self.category_map = category_map\n",
    "        \n",
    "        self.labels = []\n",
    "        for item in self.entries:\n",
    "            if item['objects']:\n",
    "                cat = item['objects'][0]['category']\n",
    "                self.labels.append(self.category_map[cat])\n",
    "            else:\n",
    "                self.labels.append(-1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.entries)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        entry = self.entries[idx]\n",
    "        pathname_from_json = entry['image']['pathname']\n",
    "        image_name = os.path.basename(pathname_from_json)\n",
    "        image_full_path = os.path.join(self.image_root, image_name)\n",
    "\n",
    "        try:\n",
    "            image = Image.open(image_full_path).convert(\"RGB\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: Image not found at {image_full_path}\")\n",
    "            return None # Will be filtered by collate_fn\n",
    "\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        for obj in entry['objects']:\n",
    "            bb = obj['bounding_box']\n",
    "            boxes.append([bb['minimum']['c'], bb['minimum']['r'], bb['maximum']['c'], bb['maximum']['r']])\n",
    "            labels.append(self.category_map[obj['category']])\n",
    "\n",
    "        boxes = torch.tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        target = {'boxes': boxes, 'labels': labels}\n",
    "        return image, target\n",
    "\n",
    "class EfficientNetDetector(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.backbone = efficientnet_b2(weights='IMAGENET1K_V1')\n",
    "        num_features = self.backbone.classifier[1].in_features\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "        self.classifier = nn.Linear(num_features, num_classes)\n",
    "        self.bbox_head = nn.Linear(num_features, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        class_scores = self.classifier(features)\n",
    "        bbox_preds = self.bbox_head(features)\n",
    "        return class_scores, bbox_preds\n",
    "\n",
    "# Custom collate_fn to filter out None values from the batch (e.g., from missing images)\n",
    "def custom_collate_fn(batch):\n",
    "    batch = list(filter(lambda x: x is not None, batch))\n",
    "    if not batch:\n",
    "        return torch.tensor([]), []\n",
    "    images = [item[0] for item in batch]\n",
    "    targets = [item[1] for item in batch]\n",
    "    images = torch.stack(images, dim=0)\n",
    "    return images, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4d5e6f",
   "metadata": {},
   "source": [
    "## Step 3: Training and Validation Functions\n",
    "This is the core logic. `train_model` handles one epoch of training. The `validate_model` function is crucially important and contains the **new, robust logic** to generate a fair, image-level ground truth for the final classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train_val_funcs",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, loader, optimizer, device, epoch, num_classes):\n",
    "    model.train()\n",
    "    running_loss, correct, total_objects = 0.0, 0, 0\n",
    "    pbar = tqdm(loader, desc=f\"Training Epoch {epoch}\")\n",
    "\n",
    "    # These loss functions must be defined to be used\n",
    "    def margin_loss(class_scores, targets, margin=0.2):\n",
    "        one_hot_targets = F.one_hot(targets.long(), num_classes=class_scores.size(-1)).float()\n",
    "        left = F.relu(margin - class_scores) * one_hot_targets\n",
    "        right = F.relu(class_scores - (1 - margin)) * (1.0 - one_hot_targets)\n",
    "        return (left + right).sum(dim=-1).mean()\n",
    "\n",
    "    def bbox_loss(preds, targets):\n",
    "        return F.smooth_l1_loss(preds, targets)\n",
    "\n",
    "    for images, targets_list in pbar:\n",
    "        if not images.numel(): continue # Skip empty batches\n",
    "        images = images.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        class_scores, bbox_preds = model(images)\n",
    "        \n",
    "        batch_class_loss = 0\n",
    "        batch_bbox_loss = 0\n",
    "        image_size = images.shape[-1]\n",
    "\n",
    "        for i in range(images.size(0)):\n",
    "            target = targets_list[i]\n",
    "            target_boxes = target['boxes'].to(device)\n",
    "            target_labels = target['labels'].to(device)\n",
    "            \n",
    "            if len(target_labels) == 0: continue\n",
    "\n",
    "            batch_class_loss += margin_loss(class_scores[i].unsqueeze(0), target_labels)\n",
    "            \n",
    "            # For bbox loss, we only compare against the first object's box for simplicity\n",
    "            target_box_norm = target_boxes[0] / torch.tensor([image_size, image_size, image_size, image_size], device=device)\n",
    "            batch_bbox_loss += bbox_loss(bbox_preds[i], target_box_norm)\n",
    "            \n",
    "            predicted = torch.argmax(class_scores[i])\n",
    "            correct += (predicted == target_labels).sum().item()\n",
    "            total_objects += len(target_labels)\n",
    "            \n",
    "        loss = batch_class_loss + 0.1 * batch_bbox_loss\n",
    "        if total_objects > 0:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "    epoch_loss = running_loss / len(loader) if len(loader) > 0 else 0\n",
    "    accuracy = 100 * correct / total_objects if total_objects > 0 else 0\n",
    "    return epoch_loss, accuracy\n",
    "\n",
    "def validate_model(model, loader, device, num_classes, category_map, return_preds=False):\n",
    "    model.eval()\n",
    "    all_labels_for_report = []\n",
    "    all_preds_for_report = []\n",
    "    pbar = tqdm(loader, desc=\"Validating\")\n",
    "\n",
    "    # Invert map to get name from index\n",
    "    idx_to_category = {v: k for k, v in category_map.items()}\n",
    "    # Get the integer labels for non-parasite classes\n",
    "    non_parasite_labels = {category_map[cat] for cat in ['red blood cell', 'leukocyte', 'difficult'] if cat in category_map}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, targets_list in pbar:\n",
    "            if not images.numel(): continue\n",
    "            images = images.to(device)\n",
    "            class_scores, _ = model(images)\n",
    "\n",
    "            for i in range(images.size(0)):\n",
    "                target_labels = targets_list[i]['labels']\n",
    "                if len(target_labels) == 0: continue\n",
    "\n",
    "                predicted_idx = torch.argmax(class_scores[i]).item()\n",
    "                all_preds_for_report.append(predicted_idx)\n",
    "\n",
    "                # --- ROBUST LOGIC FOR TRUE LABEL --- \n",
    "                parasite_labels = [lbl.item() for lbl in target_labels if lbl.item() not in non_parasite_labels]\n",
    "                \n",
    "                if parasite_labels:\n",
    "                    true_label_for_report = parasite_labels[0]\n",
    "                else:\n",
    "                    true_label_for_report = target_labels[0].item()\n",
    "                \n",
    "                all_labels_for_report.append(true_label_for_report)\n",
    "\n",
    "    if return_preds:\n",
    "        return all_labels_for_report, all_preds_for_report\n",
    "    else:\n",
    "        # Return overall accuracy if not doing a detailed report\n",
    "        accuracy = 100 * np.mean(np.array(all_labels_for_report) == np.array(all_preds_for_report))\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5e6f7g",
   "metadata": {},
   "source": [
    "## Step 4: Main Training Pipeline\n",
    "This is where we put everything together. We'll define our hyperparameters, set up the datasets and dataloaders, and then run the training loop for a set number of epochs. After training, the best model is saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "main_pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Define Hyperparameters for our single run ---\n",
    "params = {\n",
    "    'lr': 0.001,\n",
    "    'optimizer': 'Adam',\n",
    "    'batch_size': 32,\n",
    "    'image_size': 224,\n",
    "    'sampling': 'oversample' # Use oversampling to help with imbalance\n",
    "}\n",
    "NUM_EPOCHS = 10\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# --- 2. Create Datasets and Category Map ---\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((params['image_size'], params['image_size'])),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_ds = MalariaDataset(train_json_path, image_path, transform=transform)\n",
    "category_map = train_ds.category_map\n",
    "num_classes = len(category_map)\n",
    "test_ds = MalariaDataset(test_json_path, image_path, transform=transform, category_map=category_map)\n",
    "\n",
    "print(f\"Found {num_classes} classes: {category_map}\")\n",
    "\n",
    "# --- 3. Create DataLoaders (with optional oversampling) ---\n",
    "sampler = None\n",
    "if params['sampling'] == 'oversample':\n",
    "    print(\"Applying weighted random oversampling...\")\n",
    "    class_counts = np.bincount(train_ds.labels)\n",
    "    class_weights = 1. / class_counts\n",
    "    sample_weights = np.array([class_weights[t] for t in train_ds.labels])\n",
    "    sampler = WeightedRandomSampler(torch.from_numpy(sample_weights).double(), len(sample_weights))\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds, \n",
    "    batch_size=params['batch_size'], \n",
    "    sampler=sampler,\n",
    "    collate_fn=custom_collate_fn,\n",
    "    # Set shuffle=False when using a sampler\n",
    "    shuffle=sampler is None \n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_ds, \n",
    "    batch_size=params['batch_size'], \n",
    "    shuffle=False, \n",
    "    collate_fn=custom_collate_fn\n",
    ")\n",
    "\n",
    "# --- 4. Initialize Model and Optimizer ---\n",
    "model = EfficientNetDetector(num_classes=num_classes).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=params['lr'])\n",
    "\n",
    "# --- 5. Run Training Loop ---\n",
    "best_val_accuracy = 0.0\n",
    "history = {'train_loss': [], 'train_accuracy': [], 'val_accuracy': []}\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    train_loss, train_acc = train_model(model, train_loader, optimizer, DEVICE, epoch, num_classes)\n",
    "    val_acc = validate_model(model, test_loader, DEVICE, num_classes, category_map)\n",
    "    \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_accuracy'].append(train_acc)\n",
    "    history['val_accuracy'].append(val_acc)\n",
    "    \n",
    "    print(f\"Epoch {epoch} Summary: Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%\")\n",
    "    \n",
    "    if val_acc > best_val_accuracy:\n",
    "        best_val_accuracy = val_acc\n",
    "        save_path = os.path.join(models_dir, 'best_model.pth')\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(f\"🎉 New best model saved to {save_path} with accuracy: {best_val_accuracy:.2f}%\")\n",
    "\n",
    "print(\"\\n--- Training Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6f7g8h",
   "metadata": {},
   "source": [
    "## Step 5: Final Evaluation and Analysis\n",
    "Now that the model is trained, we load the best-performing version (the one saved during the epoch with the highest validation accuracy) and run a final, detailed evaluation on the test set. This gives us an unbiased assessment of its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final_eval",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Starting Final Evaluation on Test Set ---\")\n",
    "\n",
    "# --- 1. Load the Best Model State ---\n",
    "best_model_path = os.path.join(models_dir, 'best_model.pth')\n",
    "eval_model = EfficientNetDetector(num_classes=num_classes).to(DEVICE)\n",
    "eval_model.load_state_dict(torch.load(best_model_path, map_location=DEVICE))\n",
    "print(f\"Loaded best model from {best_model_path}\")\n",
    "\n",
    "# --- 2. Get Final Predictions ---\n",
    "y_true, y_pred = validate_model(eval_model, test_loader, DEVICE, num_classes, category_map, return_preds=True)\n",
    "\n",
    "# --- 3. Generate Reports ---\n",
    "class_names = [name for name, index in sorted(category_map.items(), key=lambda item: item[1])]\n",
    "labels_for_report = list(range(len(class_names)))\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\n--- Classification Report ---\")\n",
    "report = classification_report(\n",
    "    y_true, \n",
    "    y_pred, \n",
    "    target_names=class_names,\n",
    "    labels=labels_for_report,\n",
    "    zero_division=0\n",
    ")\n",
    "print(report)\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\n--- Confusion Matrix ---\")\n",
    "cm = confusion_matrix(y_true, y_pred, labels=labels_for_report)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Confusion Matrix', fontsize=16)\n",
    "plt.ylabel('Actual Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
