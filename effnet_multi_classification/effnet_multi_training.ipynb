{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a2b3c4d",
   "metadata": {},
   "source": [
    "## Setup and Configuration for Multi class Effnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed360cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torchvision import transforms\n",
    "from torchvision.models import efficientnet_b2\n",
    "\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79630615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Path: ..\\dataset\\malaria\n",
      "Train JSON Path: ..\\dataset\\malaria\\training.json\n",
      "Test JSON Path: ..\\dataset\\malaria\\test.json\n",
      "Image Path: ..\\dataset\\malaria\\images\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "root_path = os.path.join('..', 'dataset', 'malaria')\n",
    "train_json_path = os.path.join(root_path, 'training.json')\n",
    "test_json_path = os.path.join(root_path, 'test.json')\n",
    "image_path = os.path.join(root_path, 'images')\n",
    "models_dir = os.path.join('.', 'effnet_models')\n",
    "\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "print(\"Root Path:\", root_path)\n",
    "print(\"Train JSON Path:\", train_json_path)\n",
    "print(\"Test JSON Path:\", test_json_path)\n",
    "print(\"Image Path:\", image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3c4d5e",
   "metadata": {},
   "source": [
    "## Model and Dataset Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "class_definitions",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MalariaDataset(Dataset):\n",
    "    \"\"\"\n",
    "        class for mapping images with bounding boxes\n",
    "    \"\"\"\n",
    "    def __init__(self, json_path, image_root, transform=None, category_map=None):\n",
    "        with open(json_path, 'r') as f:\n",
    "            self.entries = json.load(f)\n",
    "        self.image_root = image_root\n",
    "        self.transform = transform\n",
    "\n",
    "        if category_map is None:\n",
    "            all_categories = set()\n",
    "            for item in self.entries:\n",
    "                for obj in item['objects']:\n",
    "                    all_categories.add(obj['category'])\n",
    "            self.category_map = {cat: idx for idx, cat in enumerate(sorted(list(all_categories)))}\n",
    "        else:\n",
    "            self.category_map = category_map\n",
    "        \n",
    "        self.labels = []\n",
    "        for item in self.entries:\n",
    "            if item['objects']:\n",
    "                cat = item['objects'][0]['category']\n",
    "                self.labels.append(self.category_map[cat])\n",
    "            else:\n",
    "                self.labels.append(-1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.entries)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        entry = self.entries[idx]\n",
    "        pathname_from_json = entry['image']['pathname']\n",
    "        image_name = os.path.basename(pathname_from_json)\n",
    "        image_full_path = os.path.join(self.image_root, image_name)\n",
    "\n",
    "        try:\n",
    "            image = Image.open(image_full_path).convert(\"RGB\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: Image not found at {image_full_path}\")\n",
    "            return None # Will be filtered by collate_fn\n",
    "\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        for obj in entry['objects']:\n",
    "            bb = obj['bounding_box']\n",
    "            boxes.append([bb['minimum']['c'], bb['minimum']['r'], bb['maximum']['c'], bb['maximum']['r']])\n",
    "            labels.append(self.category_map[obj['category']])\n",
    "\n",
    "        boxes = torch.tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        target = {'boxes': boxes, 'labels': labels}\n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d898ee",
   "metadata": {},
   "source": [
    "### Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc8d6b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNetDetector(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(EfficientNetDetector, self).__init__()\n",
    "        # Loading pre-trained EfficientNet-B2 as the backbone\n",
    "        self.backbone = efficientnet_b2(weights='IMAGENET1K_V1')\n",
    "        \n",
    "        # Replacing the final classifier with an identity layer\n",
    "        in_features = self.backbone.classifier[1].in_features\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "        \n",
    "        # classifier for multi-label classification\n",
    "        self.classifier = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass input through the backbone\n",
    "        features = self.backbone(x)\n",
    "        \n",
    "        # Getting class scores from the classifier\n",
    "        class_scores = self.classifier(features)\n",
    "        \n",
    "        # return the class scores\n",
    "        return class_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4d5e6f",
   "metadata": {},
   "source": [
    "## Training and Validation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "train_val_funcs",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, loader, optimizer, device, epoch, num_classes):\n",
    "    model.train()\n",
    "    running_loss, correct, total_objects = 0.0, 0, 0\n",
    "    pbar = tqdm(loader, desc=f\"Training Epoch {epoch}\")\n",
    "    \n",
    "    # the loss function BCEWithLogitsLoss is ideal for multi-label tasks as it combines Sigmoid + BCE.\n",
    "    # `pos_weight` forces the model to focus on rare classes by heavily penalizing mistakes on them.\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight_tensor)\n",
    "\n",
    "    for images, targets_list in pbar:\n",
    "        if not images.numel(): continue # Skip empty batches\n",
    "        images = images.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Getting the class scores\n",
    "        class_scores = model(images)\n",
    "        \n",
    "        # Creating a placeholder for all target labels in the batch\n",
    "        all_target_labels = torch.zeros_like(class_scores).to(device)\n",
    "\n",
    "        # Populate the multi-hot encoded tensor\n",
    "        for i, target in enumerate(targets_list):\n",
    "            labels = target['labels']\n",
    "            if len(labels) > 0:\n",
    "                all_target_labels[i, labels] = 1.0\n",
    "\n",
    "        # Calculate loss for the whole batch at once\n",
    "        loss = criterion(class_scores, all_target_labels)\n",
    "\n",
    "        if images.size(0) > 0:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Apply sigmoid to get probabilities, then threshold to get predictions\n",
    "        preds = torch.sigmoid(class_scores)\n",
    "        preds[preds >= 0.5] = 1\n",
    "        preds[preds < 0.5] = 0\n",
    "\n",
    "        # Compare if the predicted multi-hot vector exactly matches the true one\n",
    "        total_objects += images.size(0)\n",
    "        correct += (preds == all_target_labels).all(dim=1).sum().item()\n",
    "\n",
    "        pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "    epoch_loss = running_loss / len(loader) if len(loader) > 0 else 0\n",
    "    accuracy = 100 * correct / total_objects if total_objects > 0 else 0\n",
    "    return epoch_loss, accuracy\n",
    "\n",
    "def validate_model(model, loader, device, category_map, return_preds=False):\n",
    "    model.eval()\n",
    "    all_labels_for_report = []\n",
    "    all_preds_for_report = []\n",
    "    \n",
    "    # Add criterion to calculate loss\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight_tensor)\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    pbar = tqdm(loader, desc=\"Validating\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, targets_list in pbar:\n",
    "            if not images.numel(): continue\n",
    "            images = images.to(device)\n",
    "            \n",
    "            class_scores = model(images)\n",
    "            \n",
    "            # Create the true multi-hot labels for the batch\n",
    "            true_labels = torch.zeros_like(class_scores)\n",
    "            for i, target in enumerate(targets_list):\n",
    "                labels = target['labels']\n",
    "                if len(labels) > 0:\n",
    "                    true_labels[i, labels] = 1.0\n",
    "            \n",
    "            # --- NEW: Calculate and accumulate loss ---\n",
    "            loss = criterion(class_scores, true_labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Get predictions\n",
    "            preds = torch.sigmoid(class_scores)\n",
    "            preds[preds >= 0.5] = 1\n",
    "            preds[preds < 0.5] = 0\n",
    "            all_preds_for_report.extend(preds.cpu().numpy())\n",
    "            all_labels_for_report.extend(true_labels.cpu().numpy())\n",
    "\n",
    "    if return_preds:\n",
    "        return all_labels_for_report, all_preds_for_report\n",
    "    else:\n",
    "        # --- MODIFIED: Return loss and accuracy ---\n",
    "        epoch_loss = running_loss / len(loader) if len(loader) > 0 else 0\n",
    "        accuracy = 100 * np.mean(np.array(all_labels_for_report) == np.array(all_preds_for_report))\n",
    "        return epoch_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5e6f7g",
   "metadata": {},
   "source": [
    "## Main Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b1f05d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom collate_fn to filter out None values from the batch\n",
    "def custom_collate_fn(batch):\n",
    "    batch = list(filter(lambda x: x is not None, batch))\n",
    "    if not batch:\n",
    "        return torch.tensor([]), []\n",
    "    images = [item[0] for item in batch]\n",
    "    targets = [item[1] for item in batch]\n",
    "    images = torch.stack(images, dim=0)\n",
    "    return images, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7eb9f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Found 7 classes: {'difficult': 0, 'gametocyte': 1, 'leukocyte': 2, 'red blood cell': 3, 'ring': 4, 'schizont': 5, 'trophozoite': 6}\n",
      "Calculating class weights for the loss function...\n",
      "Calculated pos_weight: [ 2.5321636  7.882353  11.851064   0.         3.9508197  6.6942673\n",
      "  1.0268457]\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# --- Pre-calculation of Class Weights ---\n",
    "# This is efficient because it doesn't change between runs.\n",
    "with open(train_json_path, 'r') as f:\n",
    "    train_entries = json.load(f)\n",
    "temp_ds = MalariaDataset(train_json_path, image_path) # Temp dataset to get map\n",
    "category_map = temp_ds.category_map\n",
    "num_classes = len(category_map)\n",
    "class_names = [name for name, index in sorted(category_map.items(), key=lambda item: item[1])]\n",
    "print(f\"Found {num_classes} classes: {category_map}\")\n",
    "\n",
    "print(\"Calculating class weights for the loss function...\")\n",
    "multi_hot_labels = np.zeros((len(train_entries), num_classes), dtype=float)\n",
    "for i, entry in enumerate(train_entries):\n",
    "    for obj in entry['objects']:\n",
    "        cat_idx = category_map.get(obj['category'])\n",
    "        if cat_idx is not None:\n",
    "            multi_hot_labels[i, cat_idx] = 1.0\n",
    "positive_counts = multi_hot_labels.sum(axis=0)\n",
    "total_samples = len(train_entries)\n",
    "pos_weight = (total_samples - positive_counts) / (positive_counts + 1e-6)\n",
    "pos_weight_tensor = torch.tensor(pos_weight, dtype=torch.float).to(DEVICE)\n",
    "print(f\"Calculated pos_weight: {pos_weight_tensor.cpu().numpy()}\")\n",
    "\n",
    "\n",
    "# --- Define Hyperparameter Grid for the Search ---\n",
    "param_grid = {\n",
    "    # 'lr': [0.001, 0.0005],\n",
    "    # 'optimizer': ['Adam', 'SGD'],\n",
    "    # 'batch_size': [16, 32],\n",
    "    # 'image_size': [224],\n",
    "    # 'sampling': ['oversample', None]\n",
    "    'lr': [0.001],\n",
    "    'optimizer': ['Adam'],\n",
    "    'batch_size': [16],\n",
    "    'image_size': [224],\n",
    "    'sampling': ['oversample']\n",
    "}\n",
    "\n",
    "# --- Setup for tracking results ---\n",
    "results = []\n",
    "grid = list(ParameterGrid(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5382e5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for the sampler\n",
    "def create_sampler(train_ds):\n",
    "    class_counts = np.bincount([label for label in train_ds.labels if label != -1], minlength=num_classes)\n",
    "    class_weights = 1. / (class_counts + 1e-6)\n",
    "    sample_weights = np.array([class_weights[t] if t != -1 else 0 for t in train_ds.labels])\n",
    "    return WeightedRandomSampler(torch.from_numpy(sample_weights).double(), len(sample_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "main_pipeline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Params: {'batch_size': 16, 'image_size': 224, 'lr': 0.001, 'optimizer': 'Adam', 'sampling': 'oversample'}\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████| 76/76 [06:24<00:00,  5.06s/it, loss=0.1729]\n",
      "Validating: 100%|██████████| 8/8 [00:13<00:00,  1.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss 0.3290, Train Acc 18.29%, Val Loss 0.9776, Val Acc 45.36%\n",
      "New best model! Val Accuracy: 45.36%\n",
      "Model saved to .\\effnet_models\\model_lr-0.001_optim-Adam_bs-16_sampling-oversample.pth\n",
      "\n",
      "==================================================\n",
      "Params: {'batch_size': 16, 'image_size': 224, 'lr': 0.001, 'optimizer': 'Adam', 'sampling': None}\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████| 76/76 [06:14<00:00,  4.92s/it, loss=0.6841]\n",
      "Validating: 100%|██████████| 8/8 [00:12<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss 0.8273, Train Acc 6.79%, Val Loss 0.7904, Val Acc 74.52%\n",
      "New best model! Val Accuracy: 74.52%\n",
      "Model saved to .\\effnet_models\\model_lr-0.001_optim-Adam_bs-16_sampling-none.pth\n",
      "\n",
      "==================================================\n",
      "Params: {'batch_size': 16, 'image_size': 224, 'lr': 0.001, 'optimizer': 'SGD', 'sampling': 'oversample'}\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  70%|██████▉   | 53/76 [04:15<01:44,  4.53s/it, loss=0.8566]"
     ]
    }
   ],
   "source": [
    "# Path to the aggregated results file\n",
    "results_filepath = os.path.join(models_dir, \"grid_search_results.json\")\n",
    "\n",
    "def run_experiment(params):\n",
    "    \"\"\"Train or load a model for this set of params; append results to a single JSON.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"Params: {params}\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # Build the unique model filename for this parameter combination\n",
    "    sampling_str = params.get('sampling') if params.get('sampling') is not None else 'none'\n",
    "    model_file = f\"model_lr-{params['lr']}_optim-{params['optimizer']}_bs-{params['batch_size']}_sampling-{sampling_str}.pth\"\n",
    "    model_path = os.path.join(models_dir, model_file)\n",
    "\n",
    "    # Read existing aggregated results, if any\n",
    "    if os.path.isfile(results_filepath):\n",
    "        with open(results_filepath, \"r\") as rf:\n",
    "            aggregated_results = json.load(rf)\n",
    "    else:\n",
    "        aggregated_results = []\n",
    "\n",
    "    # See if this parameter set has already been processed and the model exists\n",
    "    existing_entry = next((e for e in aggregated_results if e.get(\"params\") == params), None)\n",
    "    if existing_entry and os.path.isfile(model_path):\n",
    "        print(f\"Found existing model and results for params {params}. Skipping training.\")\n",
    "        # Include a flag to indicate the run was skipped\n",
    "        return existing_entry | {\"skipped\": True, \"training_time_minutes\": 0.0}\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # ----- Data preparation -----\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((params['image_size'], params['image_size'])),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    train_ds = MalariaDataset(train_json_path, image_path, transform=transform, category_map=category_map)\n",
    "    val_ds   = MalariaDataset(test_json_path,  image_path, transform=transform, category_map=category_map)\n",
    "\n",
    "    sampler, shuffle = None, True\n",
    "    if params.get('sampling') == 'oversample':\n",
    "        sampler = create_sampler(train_ds)\n",
    "        shuffle = False\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=params['batch_size'], shuffle=shuffle, sampler=sampler, collate_fn=custom_collate_fn)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=params['batch_size'], shuffle=False,              collate_fn=custom_collate_fn)\n",
    "\n",
    "    # ----- Model and optimizer -----\n",
    "    model = EfficientNetDetector(num_classes=num_classes).to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=params['lr']) if params['optimizer'] == 'Adam' \\\n",
    "               else torch.optim.SGD(model.parameters(), lr=params['lr'], momentum=0.9)\n",
    "\n",
    "    # ----- Training loop -----\n",
    "    history = {'train_loss': [], 'train_accuracy': [], 'val_loss': [], 'val_accuracy': []}\n",
    "    best_val_accuracy = 0.0\n",
    "    NUM_EPOCHS = 1\n",
    "\n",
    "    for epoch in range(1, NUM_EPOCHS + 1):\n",
    "        train_loss, train_acc = train_model(model, train_loader, optimizer, DEVICE, epoch, num_classes)\n",
    "        val_loss,   val_acc   = validate_model(model, val_loader, DEVICE, category_map)\n",
    "        print(f\"Epoch {epoch}: Train Loss {train_loss:.4f}, Train Acc {train_acc:.2f}%, Val Loss {val_loss:.4f}, Val Acc {val_acc:.2f}%\")\n",
    "\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_accuracy'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_accuracy'].append(val_acc)\n",
    "\n",
    "        # Save a new best model\n",
    "        if val_acc > best_val_accuracy:\n",
    "            best_val_accuracy = val_acc\n",
    "            print(f\"New best model! Val Accuracy: {best_val_accuracy:.2f}%\")\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'params': params,\n",
    "                'best_val_accuracy': best_val_accuracy\n",
    "            }, model_path)\n",
    "            print(f\"Model saved to {model_path}\")\n",
    "\n",
    "    # ----- Update aggregated results -----\n",
    "    elapsed_time = time.time() - start_time\n",
    "    # Remove any prior entry for these params\n",
    "    aggregated_results = [e for e in aggregated_results if e.get(\"params\") != params]\n",
    "    aggregated_results.append({\n",
    "        \"params\": params,\n",
    "        \"best_accuracy\": best_val_accuracy,\n",
    "        \"training_time_minutes\": elapsed_time / 60,\n",
    "        \"history\": history\n",
    "    })\n",
    "    with open(results_filepath, \"w\") as rf:\n",
    "        json.dump(aggregated_results, rf, indent=4)\n",
    "\n",
    "    return {\n",
    "        \"params\": params,\n",
    "        \"best_accuracy\": best_val_accuracy,\n",
    "        \"training_time_minutes\": elapsed_time / 60,\n",
    "        \"history\": history,\n",
    "        \"skipped\": False\n",
    "    }\n",
    "\n",
    "\n",
    "# Define your hyperparameter grid\n",
    "param_grid = {\n",
    "    'lr': [0.001, 0.0005],\n",
    "    'optimizer': ['Adam', 'SGD'],\n",
    "    'batch_size': [16, 32],\n",
    "    'image_size': [224],\n",
    "    'sampling': ['oversample', None],\n",
    "}\n",
    "\n",
    "# Run the grid search\n",
    "all_results = []\n",
    "for params in ParameterGrid(param_grid):\n",
    "    result = run_experiment(params)\n",
    "    all_results.append(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
