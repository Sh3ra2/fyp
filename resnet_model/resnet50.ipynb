{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed360cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "\n",
    "import time\n",
    "from collections import defaultdict, Counter\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(parent_dir)\n",
    "from malaria_dataset import MalariaDataset, detection_collate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acb385e",
   "metadata": {},
   "source": [
    "# Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffd4e526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Path: ..\\dataset\\malaria\n",
      "Train JSON Path: ..\\dataset\\malaria\\training.json\n",
      "Test JSON Path: ..\\dataset\\malaria\\test.json\n",
      "Image Path: ..\\dataset\\malaria\\images\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "root_path = os.path.join('..', 'dataset', 'malaria')\n",
    "train_json_path = os.path.join(root_path, 'training.json')\n",
    "test_json_path = os.path.join(root_path, 'test.json')\n",
    "image_path = os.path.join(root_path, 'images')\n",
    "print(\"Root Path:\", root_path)\n",
    "print(\"Train JSON Path:\", train_json_path)\n",
    "print(\"Test JSON Path:\", test_json_path)\n",
    "print(\"Image Path:\", image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffab830a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models will be saved in: .\\resnet_models\n"
     ]
    }
   ],
   "source": [
    "models_dir = os.path.join('.', 'resnet_models') \n",
    "os.makedirs(models_dir, exist_ok=True) \n",
    "\n",
    "print(f\"Models will be saved in: {models_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f138abfc",
   "metadata": {},
   "source": [
    "## Deeplearning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e08118",
   "metadata": {},
   "source": [
    "### Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58ccf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create a sampler for handling class imbalance\n",
    "def create_sampler(dataset):\n",
    "    \"\"\"Creates a WeightedRandomSampler to oversample minority classes.\"\"\"\n",
    "    # Count frequency of each class in the dataset\n",
    "    class_counts = Counter(dataset.labels)\n",
    "    \n",
    "    # Remove placeholder labels if any\n",
    "    if -1 in class_counts:\n",
    "        del class_counts[-1]\n",
    "        \n",
    "    print(\"Class distribution:\", class_counts)\n",
    "\n",
    "    # Calculate weight for each class (more weight to rare classes)\n",
    "    num_samples = len(dataset.labels)\n",
    "    class_weights = {cls: num_samples / count for cls, count in class_counts.items()}\n",
    "    \n",
    "    # Assign a weight to each sample in the dataset\n",
    "    sample_weights = [class_weights.get(label, 0) for label in dataset.labels]\n",
    "\n",
    "    # Create the sampler\n",
    "    sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "    return sampler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6bdf75",
   "metadata": {},
   "source": [
    "### 1. Resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af416940",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetDetector(nn.Module):\n",
    "    # Your ResNetDetector class here...\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.backbone = resnet50(weights='IMAGENET1K_V1')\n",
    "        # Replace the final fully connected layer\n",
    "        num_features = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Identity() # Remove the original classifier\n",
    "\n",
    "        # New heads for task\n",
    "        self.classifier = nn.Linear(num_features, num_classes)\n",
    "        self.bbox_head = nn.Linear(num_features, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        class_scores = self.classifier(features)\n",
    "        bbox_preds = self.bbox_head(features)\n",
    "        return class_scores, bbox_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce60d4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your loss functions and collate_fn here...\n",
    "def margin_loss(class_scores, targets, margin=0.2):\n",
    "    one_hot_targets = F.one_hot(targets.long(), num_classes=class_scores.size(-1)).float()\n",
    "    left = F.relu(margin - class_scores) * one_hot_targets\n",
    "    right = F.relu(class_scores - (1 - margin)) * (1.0 - one_hot_targets)\n",
    "    return (left + right).sum(dim=-1).mean()\n",
    "\n",
    "def bbox_loss(preds, targets):\n",
    "    if preds.dim() == 1:\n",
    "        preds = preds.unsqueeze(0)\n",
    "    num_preds, num_targets = preds.size(0), targets.size(0)\n",
    "    if num_preds > num_targets:\n",
    "        padding = torch.zeros((num_preds - num_targets, 4), device=targets.device)\n",
    "        targets = torch.cat([targets, padding], dim=0)\n",
    "    elif num_targets > num_preds:\n",
    "        padding = torch.zeros((num_targets - num_preds, 4), device=preds.device)\n",
    "        preds = torch.cat([preds, padding], dim=0)\n",
    "    return F.smooth_l1_loss(preds, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4417c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your train and validate functions here...\n",
    "def train_model(model, train_loader, optimizer, epoch, device, image_size):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    pbar = tqdm(train_loader, desc=f\"Training Epoch {epoch}\", unit=\"batch\")\n",
    "    for images, targets_list in pbar:\n",
    "        images = images.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        class_scores, bbox_preds = model(images)\n",
    "        \n",
    "        batch_class_loss = 0\n",
    "        batch_bbox_loss = 0\n",
    "        \n",
    "        for i in range(images.size(0)):\n",
    "            target = targets_list[i]\n",
    "            target_boxes = target['boxes'].to(device)\n",
    "            target_labels = target['labels'].to(device)\n",
    "            \n",
    "            if len(target_labels) == 0: continue\n",
    "            \n",
    "            # Normalize bounding boxes\n",
    "            target_boxes_norm = target_boxes / torch.tensor([image_size, image_size, image_size, image_size], device=device)\n",
    "\n",
    "            batch_class_loss += margin_loss(class_scores[i].unsqueeze(0), target_labels)\n",
    "            batch_bbox_loss += bbox_loss(bbox_preds[i], target_boxes_norm)\n",
    "\n",
    "            predicted = torch.argmax(class_scores[i])\n",
    "            correct += (predicted == target_labels).sum().item()\n",
    "            total += len(target_labels)\n",
    "        \n",
    "        loss = batch_class_loss + 0.1 * batch_bbox_loss\n",
    "        if total > 0:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    accuracy = 100 * correct / total if total > 0 else 0\n",
    "    print(f\"Train Epoch: {epoch}, Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "    return epoch_loss, accuracy\n",
    "\n",
    "def validate_model(model, val_loader, device, image_size): \n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, targets_list in tqdm(val_loader, desc=\"Validating\", unit=\"batch\"):\n",
    "            images = images.to(device)\n",
    "            class_scores, bbox_preds = model(images)\n",
    "\n",
    "            for i in range(images.size(0)):\n",
    "                target = targets_list[i]\n",
    "                target_boxes = target['boxes'].to(device)\n",
    "                target_labels = target['labels'].to(device)\n",
    "                \n",
    "                if len(target_labels) == 0: continue\n",
    "                \n",
    "                target_boxes_norm = target_boxes / torch.tensor([image_size, image_size, image_size, image_size], device=device)\n",
    "\n",
    "                loss = margin_loss(class_scores[i].unsqueeze(0), target_labels) + \\\n",
    "                       0.1 * bbox_loss(bbox_preds[i], target_boxes_norm)\n",
    "                running_loss += loss.item()\n",
    "                \n",
    "                predicted = torch.argmax(class_scores[i])\n",
    "                correct += (predicted == target_labels).sum().item()\n",
    "                total += len(target_labels)\n",
    "\n",
    "    epoch_loss = running_loss / len(val_loader)\n",
    "    accuracy = 100 * correct / total if total > 0 else 0\n",
    "    print(f\"Validation Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "    return epoch_loss, accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705d29ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(params):\n",
    "    \"\"\"\n",
    "    Runs a full training and validation experiment for a given set of hyperparameters.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"STARTING EXPERIMENT with params: {params}\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    #   1. Setup Device and Create Transforms based on params  \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    image_size = params['image_size']\n",
    "\n",
    "    \n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((image_size, image_size)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.Resize((image_size, image_size)),\n",
    "        transforms.ToTensor(),  \n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    #   2. Create Datasets and DataLoaders  \n",
    "    train_ds = MalariaDataset(train_json_path, image_path, transform=train_transform, image_size=image_size)\n",
    "    test_ds = MalariaDataset(test_json_path, image_path, transform=test_transform, category_map=train_ds.category_map, image_size=image_size)\n",
    "    \n",
    "    sampler = None\n",
    "    shuffle = True\n",
    "    if params['sampling'] == 'oversample':\n",
    "        print(\"Applying weighted oversampling...\")\n",
    "        sampler = create_sampler(train_ds)\n",
    "        shuffle = False\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_ds, batch_size=params['batch_size'], shuffle=shuffle, sampler=sampler,\n",
    "        collate_fn=detection_collate, \n",
    "        num_workers=0\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        test_ds, batch_size=params['batch_size'], shuffle=False, \n",
    "        collate_fn=detection_collate, \n",
    "        num_workers=0\n",
    "    )\n",
    "\n",
    "    #   3. Initialize Model and Optimizer  \n",
    "    model = ResNetDetector(num_classes=len(train_ds.category_map)).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=params['lr']) if params['optimizer'] == 'Adam' \\\n",
    "        else optim.SGD(model.parameters(), lr=params['lr'], momentum=0.9)\n",
    "\n",
    "    #   4. Training Loop  \n",
    "    best_val_accuracy = 0.0\n",
    "    num_epochs = 10\n",
    "    best_val_accuracy = 0.0\n",
    "    num_epochs = 10 \n",
    "    \n",
    "    #   (1) INITIALIZE HISTORY  \n",
    "    history = {\n",
    "        'train_loss': [], 'train_accuracy': [],\n",
    "        'val_loss': [], 'val_accuracy': []\n",
    "    }\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        # Pass image_size to your train/validate functions if they need it for normalization\n",
    "        train_loss, train_accuracy = train_model(model, train_loader, optimizer, epoch, device, image_size)\n",
    "        val_loss, val_accuracy = validate_model(model, val_loader, device, image_size)\n",
    "\n",
    "        #   (2) RECORD METRICS EACH EPOCH  \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_accuracy'].append(train_accuracy)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_accuracy'].append(val_accuracy)\n",
    "\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            print(f\"New best model! Val Accuracy: {best_val_accuracy:.2f}%\")\n",
    "            \n",
    "            #   5. Save the best model for this experiment  \n",
    "            model_filename = (f\"model_lr_{params['lr']}_optim_{params['optimizer']}_\"\n",
    "                            f\"sampling_{params['sampling']}_size_{params['image_size']}.pth\")\n",
    "            save_path = os.path.join(models_dir, model_filename)\n",
    "\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'best_val_accuracy': best_val_accuracy,\n",
    "                'params': params\n",
    "            }, save_path)\n",
    "            print(f\"Model saved to {save_path}\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Finished experiment. Best validation accuracy: {best_val_accuracy:.2f}%\")\n",
    "    print(f\"Total training time: {elapsed_time / 60:.2f} minutes\")\n",
    "    \n",
    "    # plot_metrics(history, params)\n",
    "    return {\n",
    "        'params': params,\n",
    "        'best_accuracy': best_val_accuracy,\n",
    "        'training_time_minutes': elapsed_time / 60,\n",
    "        'history' : history\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80014d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Helper function to manage results  \n",
    "def get_completed_experiments(results_path):\n",
    "    \"\"\"Loads existing results and returns a set of completed parameter combos.\"\"\"\n",
    "    if not os.path.exists(results_path):\n",
    "        return set(), []\n",
    "    \n",
    "    with open(results_path, 'r') as f:\n",
    "        try:\n",
    "            existing_results = json.load(f)\n",
    "        except json.JSONDecodeError:\n",
    "            return set(), [] # File is empty or corrupt\n",
    "\n",
    "    # Create a unique, hashable representation of each param dictionary\n",
    "    completed = set(tuple(sorted(res['params'].items())) for res in existing_results)\n",
    "    print(f\"Found {len(completed)} completed experiments in {results_path}.\")\n",
    "    return completed, existing_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82a24e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14 completed experiments in .\\resnet_models\\grid_search_results.json.\n",
      "Starting Grid Search. Total experiments to run: 16\n",
      "\n",
      "--- Skipping Experiment 1/16 (already done) ---\n",
      "Params: {'lr': 0.001, 'optimizer': 'Adam', 'batch_size': 32, 'sampling': 'none', 'image_size': 128}\n",
      "\n",
      "--- Skipping Experiment 2/16 (already done) ---\n",
      "Params: {'lr': 0.001, 'optimizer': 'Adam', 'batch_size': 32, 'sampling': 'none', 'image_size': 224}\n",
      "\n",
      "--- Skipping Experiment 3/16 (already done) ---\n",
      "Params: {'lr': 0.001, 'optimizer': 'Adam', 'batch_size': 32, 'sampling': 'oversample', 'image_size': 128}\n",
      "\n",
      "--- Skipping Experiment 4/16 (already done) ---\n",
      "Params: {'lr': 0.001, 'optimizer': 'Adam', 'batch_size': 32, 'sampling': 'oversample', 'image_size': 224}\n",
      "\n",
      "--- Skipping Experiment 5/16 (already done) ---\n",
      "Params: {'lr': 0.001, 'optimizer': 'SGD', 'batch_size': 32, 'sampling': 'none', 'image_size': 128}\n",
      "\n",
      "--- Skipping Experiment 6/16 (already done) ---\n",
      "Params: {'lr': 0.001, 'optimizer': 'SGD', 'batch_size': 32, 'sampling': 'none', 'image_size': 224}\n",
      "\n",
      "--- Skipping Experiment 7/16 (already done) ---\n",
      "Params: {'lr': 0.001, 'optimizer': 'SGD', 'batch_size': 32, 'sampling': 'oversample', 'image_size': 128}\n",
      "\n",
      "--- Skipping Experiment 8/16 (already done) ---\n",
      "Params: {'lr': 0.001, 'optimizer': 'SGD', 'batch_size': 32, 'sampling': 'oversample', 'image_size': 224}\n",
      "\n",
      "--- Skipping Experiment 9/16 (already done) ---\n",
      "Params: {'lr': 0.0001, 'optimizer': 'Adam', 'batch_size': 32, 'sampling': 'none', 'image_size': 128}\n",
      "\n",
      "--- Skipping Experiment 10/16 (already done) ---\n",
      "Params: {'lr': 0.0001, 'optimizer': 'Adam', 'batch_size': 32, 'sampling': 'none', 'image_size': 224}\n",
      "\n",
      "--- Skipping Experiment 11/16 (already done) ---\n",
      "Params: {'lr': 0.0001, 'optimizer': 'Adam', 'batch_size': 32, 'sampling': 'oversample', 'image_size': 128}\n",
      "\n",
      "--- Skipping Experiment 12/16 (already done) ---\n",
      "Params: {'lr': 0.0001, 'optimizer': 'Adam', 'batch_size': 32, 'sampling': 'oversample', 'image_size': 224}\n",
      "\n",
      "--- Skipping Experiment 13/16 (already done) ---\n",
      "Params: {'lr': 0.0001, 'optimizer': 'SGD', 'batch_size': 32, 'sampling': 'none', 'image_size': 128}\n",
      "\n",
      "--- Skipping Experiment 14/16 (already done) ---\n",
      "Params: {'lr': 0.0001, 'optimizer': 'SGD', 'batch_size': 32, 'sampling': 'none', 'image_size': 224}\n",
      "\n",
      "--- Running Experiment 15/16 ---\n",
      "\n",
      "==================================================\n",
      "STARTING EXPERIMENT with params: {'lr': 0.0001, 'optimizer': 'SGD', 'batch_size': 32, 'sampling': 'oversample', 'image_size': 128}\n",
      "==================================================\n",
      "Applying weighted oversampling...\n",
      "Class distribution: Counter({3: 1186, 6: 6, 4: 5, 0: 5, 5: 4, 1: 2})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████| 38/38 [03:20<00:00,  5.29s/batch, loss=12.2503]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1, Loss: 20.0301, Accuracy: 90.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 4/4 [00:11<00:00,  2.90s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 18.4156, Accuracy: 94.80%\n",
      "New best model! Val Accuracy: 94.80%\n",
      "Model saved to .\\resnet_models\\model_lr_0.0001_optim_SGD_sampling_oversample_size_128.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████| 38/38 [02:53<00:00,  4.56s/batch, loss=12.3184]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2, Loss: 16.1177, Accuracy: 84.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 4/4 [00:08<00:00,  2.10s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 18.5833, Accuracy: 94.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████| 38/38 [02:50<00:00,  4.49s/batch, loss=12.1757]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3, Loss: 16.0528, Accuracy: 83.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 4/4 [00:08<00:00,  2.17s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 18.4293, Accuracy: 94.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|██████████| 38/38 [02:56<00:00,  4.64s/batch, loss=12.1387]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4, Loss: 15.9234, Accuracy: 74.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 4/4 [00:08<00:00,  2.24s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 17.9650, Accuracy: 94.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5: 100%|██████████| 38/38 [02:56<00:00,  4.64s/batch, loss=12.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5, Loss: 15.8654, Accuracy: 74.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 4/4 [00:08<00:00,  2.15s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 17.7253, Accuracy: 90.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6: 100%|██████████| 38/38 [02:54<00:00,  4.60s/batch, loss=11.8343]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6, Loss: 15.8001, Accuracy: 80.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 4/4 [00:08<00:00,  2.13s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 17.7130, Accuracy: 86.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7: 100%|██████████| 38/38 [02:47<00:00,  4.41s/batch, loss=11.8736]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7, Loss: 15.9645, Accuracy: 79.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 4/4 [00:08<00:00,  2.10s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 17.7004, Accuracy: 89.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8: 100%|██████████| 38/38 [02:47<00:00,  4.40s/batch, loss=12.0019]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8, Loss: 15.8166, Accuracy: 71.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 4/4 [00:08<00:00,  2.13s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 18.1247, Accuracy: 93.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9: 100%|██████████| 38/38 [02:48<00:00,  4.44s/batch, loss=11.8170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9, Loss: 15.7453, Accuracy: 71.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 4/4 [00:08<00:00,  2.12s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 18.8768, Accuracy: 80.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10: 100%|██████████| 38/38 [02:47<00:00,  4.42s/batch, loss=11.9121]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10, Loss: 15.7546, Accuracy: 71.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 4/4 [00:08<00:00,  2.10s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 18.4109, Accuracy: 91.02%\n",
      "Finished experiment. Best validation accuracy: 94.80%\n",
      "Total training time: 30.59 minutes\n",
      "Progress saved to .\\resnet_models\\grid_search_results.json\n",
      "\n",
      "--- Running Experiment 16/16 ---\n",
      "\n",
      "==================================================\n",
      "STARTING EXPERIMENT with params: {'lr': 0.0001, 'optimizer': 'SGD', 'batch_size': 32, 'sampling': 'oversample', 'image_size': 224}\n",
      "==================================================\n",
      "Applying weighted oversampling...\n",
      "Class distribution: Counter({3: 1186, 6: 6, 4: 5, 0: 5, 5: 4, 1: 2})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████| 38/38 [05:39<00:00,  8.94s/batch, loss=6.5172] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1, Loss: 9.6664, Accuracy: 86.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 4/4 [00:14<00:00,  3.54s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 9.7571, Accuracy: 94.80%\n",
      "New best model! Val Accuracy: 94.80%\n",
      "Model saved to .\\resnet_models\\model_lr_0.0001_optim_SGD_sampling_oversample_size_224.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████| 38/38 [05:42<00:00,  9.01s/batch, loss=6.2274]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2, Loss: 8.4235, Accuracy: 69.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 4/4 [00:14<00:00,  3.75s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 9.7217, Accuracy: 91.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████| 38/38 [05:53<00:00,  9.32s/batch, loss=6.3371]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3, Loss: 8.3669, Accuracy: 71.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 4/4 [00:14<00:00,  3.73s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 9.8202, Accuracy: 91.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|██████████| 38/38 [05:50<00:00,  9.22s/batch, loss=6.1672]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4, Loss: 8.3234, Accuracy: 68.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 4/4 [00:14<00:00,  3.73s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 9.6633, Accuracy: 75.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5: 100%|██████████| 38/38 [05:51<00:00,  9.24s/batch, loss=6.2275]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5, Loss: 8.3242, Accuracy: 41.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 4/4 [00:15<00:00,  3.81s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 9.6073, Accuracy: 74.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6: 100%|██████████| 38/38 [05:49<00:00,  9.21s/batch, loss=6.2215]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6, Loss: 8.3180, Accuracy: 59.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 4/4 [00:15<00:00,  3.76s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 9.6281, Accuracy: 94.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7: 100%|██████████| 38/38 [05:51<00:00,  9.24s/batch, loss=6.3747]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7, Loss: 8.3176, Accuracy: 43.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 4/4 [00:15<00:00,  3.81s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 9.6978, Accuracy: 94.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8: 100%|██████████| 38/38 [05:55<00:00,  9.35s/batch, loss=6.3409]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8, Loss: 8.2921, Accuracy: 47.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 4/4 [00:14<00:00,  3.74s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 9.5252, Accuracy: 88.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9: 100%|██████████| 38/38 [05:49<00:00,  9.20s/batch, loss=6.2537]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9, Loss: 8.2927, Accuracy: 42.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 4/4 [00:14<00:00,  3.73s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 9.5897, Accuracy: 94.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10: 100%|██████████| 38/38 [05:55<00:00,  9.34s/batch, loss=6.2562]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10, Loss: 8.2644, Accuracy: 44.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 4/4 [00:14<00:00,  3.73s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 9.6061, Accuracy: 81.81%\n",
      "Finished experiment. Best validation accuracy: 94.80%\n",
      "Total training time: 60.82 minutes\n",
      "Progress saved to .\\resnet_models\\grid_search_results.json\n",
      "\n",
      "\n",
      "##############################\n",
      "GRID SEARCH COMPLETE\n",
      "##############################\n",
      "Acc: 94.80% | Time: 31.35 min | Params: {'lr': 0.001, 'optimizer': 'Adam', 'batch_size': 32, 'sampling': 'none', 'image_size': 128}\n",
      "Acc: 94.80% | Time: 81.28 min | Params: {'lr': 0.001, 'optimizer': 'Adam', 'batch_size': 32, 'sampling': 'none', 'image_size': 224}\n",
      "Acc: 94.80% | Time: 31.81 min | Params: {'lr': 0.001, 'optimizer': 'Adam', 'batch_size': 32, 'sampling': 'oversample', 'image_size': 128}\n",
      "Acc: 94.80% | Time: 61.68 min | Params: {'lr': 0.001, 'optimizer': 'Adam', 'batch_size': 32, 'sampling': 'oversample', 'image_size': 224}\n",
      "Acc: 94.80% | Time: 31.51 min | Params: {'lr': 0.001, 'optimizer': 'SGD', 'batch_size': 32, 'sampling': 'none', 'image_size': 128}\n",
      "Acc: 94.80% | Time: 61.93 min | Params: {'lr': 0.001, 'optimizer': 'SGD', 'batch_size': 32, 'sampling': 'none', 'image_size': 224}\n",
      "Acc: 94.80% | Time: 31.15 min | Params: {'lr': 0.001, 'optimizer': 'SGD', 'batch_size': 32, 'sampling': 'oversample', 'image_size': 128}\n",
      "Acc: 94.80% | Time: 57.23 min | Params: {'lr': 0.001, 'optimizer': 'SGD', 'batch_size': 32, 'sampling': 'oversample', 'image_size': 224}\n",
      "Acc: 94.80% | Time: 28.58 min | Params: {'lr': 0.0001, 'optimizer': 'Adam', 'batch_size': 32, 'sampling': 'oversample', 'image_size': 128}\n",
      "Acc: 94.80% | Time: 65.84 min | Params: {'lr': 0.0001, 'optimizer': 'SGD', 'batch_size': 32, 'sampling': 'none', 'image_size': 224}\n",
      "Acc: 94.80% | Time: 30.59 min | Params: {'lr': 0.0001, 'optimizer': 'SGD', 'batch_size': 32, 'sampling': 'oversample', 'image_size': 128}\n",
      "Acc: 94.80% | Time: 60.82 min | Params: {'lr': 0.0001, 'optimizer': 'SGD', 'batch_size': 32, 'sampling': 'oversample', 'image_size': 224}\n",
      "Acc: 94.12% | Time: 31.68 min | Params: {'lr': 0.0001, 'optimizer': 'SGD', 'batch_size': 32, 'sampling': 'none', 'image_size': 128}\n",
      "Acc: 93.63% | Time: 29.30 min | Params: {'lr': 0.0001, 'optimizer': 'Adam', 'batch_size': 32, 'sampling': 'none', 'image_size': 128}\n",
      "Acc: 91.17% | Time: 57.58 min | Params: {'lr': 0.0001, 'optimizer': 'Adam', 'batch_size': 32, 'sampling': 'oversample', 'image_size': 224}\n",
      "Acc: 55.44% | Time: 505.72 min | Params: {'lr': 0.0001, 'optimizer': 'Adam', 'batch_size': 32, 'sampling': 'none', 'image_size': 224}\n",
      "\n",
      "All results saved to .\\resnet_models\\grid_search_results.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the grid of hyperparameters to search\n",
    "param_grid = {\n",
    "    'lr': [0.001, 0.0001],\n",
    "    'optimizer': ['Adam', 'SGD'],\n",
    "    'batch_size': [32],\n",
    "    'sampling': ['none', 'oversample'],\n",
    "    'image_size': [128, 224] # <-- EXPERIMENT WITH SIZES\n",
    "}\n",
    "results_path = os.path.join(models_dir, 'grid_search_results.json')\n",
    "\n",
    "#   2. Generate all experiment configurations  \n",
    "keys, values = zip(*param_grid.items())\n",
    "experiments = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "#   3. Load previous progress (CHECKPOINTING)  \n",
    "completed_params, all_results = get_completed_experiments(results_path)\n",
    "\n",
    "print(f\"Starting Grid Search. Total experiments to run: {len(experiments)}\")\n",
    "#   4. Run the experiments  \n",
    "for i, params in enumerate(experiments):\n",
    "    # Create a unique key for the current parameter set\n",
    "    current_param_key = tuple(sorted(params.items()))\n",
    "\n",
    "    # Check if this experiment has already been completed\n",
    "    if current_param_key in completed_params:\n",
    "        print(f\"\\n  Skipping Experiment {i+1}/{len(experiments)} (already done)  \")\n",
    "        print(f\"Params: {params}\")\n",
    "        continue\n",
    "\n",
    "    # If not skipped, run the experiment\n",
    "    print(f\"\\n  Running Experiment {i+1}/{len(experiments)}  \")\n",
    "    result = run_experiment(params)\n",
    "    all_results.append(result)\n",
    "\n",
    "    #   5. Save progress after EACH experiment (CHECKPOINTING)  \n",
    "    try:\n",
    "        with open(results_path, 'w') as f:\n",
    "            json.dump(all_results, f, indent=4)\n",
    "        print(f\"Progress saved to {results_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving progress: {e}\")\n",
    "\n",
    "\n",
    "#   6. Print and save final results  \n",
    "print(\"\\n\\n\" + \"#\"*30)\n",
    "print(\"GRID SEARCH COMPLETE\")\n",
    "print(\"#\"*30)\n",
    "\n",
    "sorted_results = sorted(all_results, key=lambda x: x.get('best_accuracy', 0), reverse=True)\n",
    "\n",
    "for res in sorted_results:\n",
    "    print(f\"Acc: {res.get('best_accuracy', 0):.2f}% | \"\n",
    "            f\"Time: {res.get('training_time_minutes', 0):.2f} min | \"\n",
    "            f\"Params: {res.get('params', {})}\")\n",
    "\n",
    "print(f\"\\nAll results saved to {results_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
