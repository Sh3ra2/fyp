{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59efefcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from skimage.feature import hog\n",
    "from pathlib import Path\n",
    "from skimage import feature\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import joblib\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d51536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Path: dataset\\malaria\n",
      "Train Base Path: dataset\\malaria\\training_ds\n",
      "Test Base Path: dataset\\malaria\\testing_ds\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "root_path = os.path.join('dataset', 'malaria')\n",
    "train_base_path = os.path.join(root_path, 'training_ds')\n",
    "test_base_path = os.path.join(root_path, 'testing_ds')\n",
    "\n",
    "FEATURES_DIR = os.path.join(root_path, 'extracted_features')\n",
    "os.makedirs(FEATURES_DIR, exist_ok=True)\n",
    "\n",
    "# image_sizes = [128,256]\n",
    "image_sizes = [128]\n",
    "\n",
    "print(\"Root Path:\", root_path)\n",
    "print(\"Train Base Path:\", train_base_path)\n",
    "print(\"Test Base Path:\", test_base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524c7ba5",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd1a8a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Feature extractors ---\n",
    "def extract_color_histogram(image, bins=(8, 8, 8)):\n",
    "    # This function now accepts an 'image' object, not an 'image_path'\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    hist = cv2.calcHist([hsv], [0, 1, 2], None, bins, [0, 180, 0, 256, 0, 256])\n",
    "    cv2.normalize(hist, hist)\n",
    "    return hist.flatten()\n",
    "\n",
    "def extract_hog_features(image, pixels_per_cell=(16, 16), cells_per_block=(2, 2)):\n",
    "    # This function now accepts an 'image' object, not an 'image_path'\n",
    "    # It also expects the image to be the correct size already.\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    features = feature.hog(gray_image, pixels_per_cell=pixels_per_cell,\n",
    "                           cells_per_block=cells_per_block, visualize=False)\n",
    "    return features\n",
    "\n",
    "def extract_lbp_features(image, numPoints=24, radius=8, eps=1e-7):\n",
    "    # This function was already correct! No changes needed here.\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    lbp = feature.local_binary_pattern(gray, numPoints, radius, method=\"uniform\")\n",
    "    (hist, _) = np.histogram(lbp.ravel(), bins=np.arange(0, numPoints + 3))\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= (hist.sum() + eps)\n",
    "    return hist\n",
    "\n",
    "# --- Dictionary of Feature Extractors ---\n",
    "# Make sure the key for your color histogram is 'HIST' if you use it.\n",
    "feature_extrators = {\n",
    "    'HOG': extract_hog_features,\n",
    "    'LBP': extract_lbp_features,\n",
    "    'HIST': extract_color_histogram \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6bb1a543",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_directory(directory_path):\n",
    "    \"\"\"Loads image paths and labels into a DataFrame.\"\"\"\n",
    "    print(f\"Loading image paths from: {directory_path}\")\n",
    "    data_list = []\n",
    "    classes = [d for d in os.listdir(directory_path) if os.path.isdir(os.path.join(directory_path, d))]\n",
    "    for label in classes:\n",
    "        class_dir = os.path.join(directory_path, label)\n",
    "        for filename in os.listdir(class_dir):\n",
    "            if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                full_path = os.path.join(class_dir, filename)\n",
    "                data_list.append({'image_path': full_path, 'label': label})\n",
    "    return pd.DataFrame(data_list)\n",
    "\n",
    "\n",
    "# In Cell 2 (Helper and Feature Extractor Functions)\n",
    "def process_and_extract(df, extractor_fn):\n",
    "    \"\"\"\n",
    "    Loops through a DataFrame, loads images, and applies a feature extractor.\n",
    "    This version includes error handling to skip problematic files.\n",
    "    \"\"\"\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "    \n",
    "    for index, row in tqdm(df.iterrows(), total=len(df), desc=f\"Extracting features\"):\n",
    "        try:\n",
    "            # 1. Load the image\n",
    "            image = cv2.imread(row['image_path'])\n",
    "            \n",
    "            # 2. Check if image loading was successful\n",
    "            if image is None:\n",
    "                print(f\"Warning: Could not read image file, skipping: {row['image_path']}\")\n",
    "                continue # Skip to the next image\n",
    "            \n",
    "            # 3. Apply the feature extractor\n",
    "            features = extractor_fn(image)\n",
    "            \n",
    "            # 4. Append the results\n",
    "            features_list.append(features)\n",
    "            labels_list.append(row['label'])\n",
    "\n",
    "        except Exception as e:\n",
    "            # Catch any other unexpected errors during processing\n",
    "            print(f\"Error processing file {row['image_path']}. Error: {e}. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "    return np.array(features_list), np.array(labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05a6ff10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 128x128 images...\n",
      "Loading image paths from: dataset\\malaria\\training_ds\\resized_128\n",
      "Loading image paths from: dataset\\malaria\\testing_ds\\resized_128\n",
      "Features for 128_HOG already exist. Skipping.\n",
      "Features for 128_LBP already exist. Skipping.\n",
      "Features for 128_HIST already exist. Skipping.\n"
     ]
    }
   ],
   "source": [
    "for size in image_sizes:\n",
    "    print(f\"\\nProcessing {size}x{size} images...\")\n",
    "    train_df = load_data_from_directory(os.path.join(train_base_path, f'resized_{size}'))\n",
    "    test_df = load_data_from_directory(os.path.join(test_base_path, f'resized_{size}'))\n",
    "\n",
    "    # Initialize and fit the LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "    le.fit(train_df['label'])\n",
    "\n",
    "    # *** THE FIX IS ON THE NEXT LINE ***\n",
    "    for name, func in feature_extrators.items(): # Corrected from 'feature_extrators'\n",
    "        output_path = os.path.join(FEATURES_DIR, f\"{size}_{name}_features.pkl\")\n",
    "        \n",
    "        # This makes the cell resumable\n",
    "        if os.path.exists(output_path):\n",
    "            print(f\"Features for {size}_{name} already exist. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"--- Extracting {name} features for {size}x{size} images ---\")\n",
    "        X_train, y_train_labels = process_and_extract(train_df, func)\n",
    "        X_test, y_test_labels = process_and_extract(test_df, func)\n",
    "\n",
    "        # Encode labels\n",
    "        y_train_encoded = le.transform(y_train_labels)\n",
    "        y_test_encoded = le.transform(y_test_labels)\n",
    "\n",
    "        # Save everything needed for training in one file\n",
    "        data_to_save = {\n",
    "            'X_train': X_train, 'y_train': y_train_encoded,\n",
    "            'X_test': X_test, 'y_test': y_test_encoded,\n",
    "            'label_encoder': le\n",
    "        }\n",
    "\n",
    "        print(f\"Saving features to {output_path}...\")\n",
    "        joblib.dump(data_to_save, output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
