{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhF79Tx4jz9S"
      },
      "source": [
        "# Phase 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import random\n",
        "from PIL import Image, ImageDraw\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from torch.utils.data.dataloader import default_collate\n",
        "from torchvision import transforms\n",
        "from torchvision.models import resnet18\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.nn import functional as F\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "root_path = r\"dataset\\malaria\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jVeo2BE6rTO",
        "outputId": "cecd63d7-3b45-4797-d84c-83b2e3c336d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scanning for images in 'dataset\\malaria\\resized_images_by_classes'...\n",
            "\n",
            "Image counts per class:\n",
            "difficult: 441 images\n",
            "gametocyte: 144 images\n",
            "leukocyte: 103 images\n",
            "red_blood_cell: 77418 images\n",
            "ring: 353 images\n",
            "schizont: 179 images\n",
            "trophozoite: 1473 images\n",
            "\n",
            "Total number of images: 80111\n",
            "Total number of classes: 7\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def count_images_per_class(base_folder):\n",
        "    \"\"\"\n",
        "    Counts the number of images in each class folder within the base directory.\n",
        "    Returns a dictionary with class names and their image counts.\n",
        "    \"\"\"\n",
        "    if not os.path.isdir(base_folder):\n",
        "        print(f\"Error: Directory not found at '{base_folder}'\")\n",
        "        return None\n",
        "\n",
        "    class_counts = {}\n",
        "    print(f\"Scanning for images in '{base_folder}'...\")\n",
        "\n",
        "    # os.walk will traverse the directory tree\n",
        "    for root, _, files in os.walk(base_folder):\n",
        "        class_name = os.path.basename(root)\n",
        "\n",
        "        # Skip the top-level directory itself\n",
        "        if class_name == os.path.basename(base_folder):\n",
        "            continue\n",
        "\n",
        "        # Count images with supported extensions\n",
        "        image_count = sum(1 for filename in files\n",
        "                         if filename.lower().endswith(('.png', '.jpg', '.jpeg')))\n",
        "\n",
        "        if image_count > 0:  # Only add classes with images\n",
        "            class_counts[class_name] = image_count\n",
        "\n",
        "    return class_counts\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Define the path to your folder of images\n",
        "    try:\n",
        "        DATA_DIR = os.path.join(root_path, 'resized_images_by_classes')\n",
        "\n",
        "    except NameError:\n",
        "        DATA_DIR = 'resized_images_by_classeseseseseses'  # Fallback if root_path isn't defined\n",
        "\n",
        "    # Get the counts of images per class\n",
        "    class_counts = count_images_per_class(DATA_DIR)\n",
        "\n",
        "    if class_counts:\n",
        "        print(\"\\nImage counts per class:\")\n",
        "        total_images = 0\n",
        "        for class_name, count in sorted(class_counts.items()):\n",
        "            print(f\"{class_name}: {count} images\")\n",
        "            total_images += count\n",
        "        print(f\"\\nTotal number of images: {total_images}\")\n",
        "        print(f\"Total number of classes: {len(class_counts)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiShQ5gaZoGN"
      },
      "source": [
        "## Data sampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "tgIZtPfLZlLb"
      },
      "outputs": [],
      "source": [
        "def get_image_paths_and_labels(base_folder):\n",
        "    \"\"\"\n",
        "    Walks through subdirectories and collects image paths and their corresponding\n",
        "    class labels derived from the folder names.\n",
        "    \"\"\"\n",
        "    if not os.path.isdir(base_folder):\n",
        "        print(f\"Error: Directory not found at '{base_folder}'\")\n",
        "        return None\n",
        "\n",
        "    image_data = []\n",
        "    print(f\"Scanning for images in '{base_folder}'...\")\n",
        "\n",
        "    # os.walk will traverse the directory tree\n",
        "    for root, _, files in os.walk(base_folder):\n",
        "        class_name = os.path.basename(root)\n",
        "\n",
        "        # Skip the top-level directory itself, only process class subfolders\n",
        "        if class_name == os.path.basename(base_folder):\n",
        "            continue\n",
        "\n",
        "        for filename in files:\n",
        "            if filename.lower().endswith(('.png', '.jpg', 'jpeg')):\n",
        "                image_path = os.path.join(root, filename)\n",
        "                image_data.append((image_path, class_name))\n",
        "\n",
        "    return image_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scanning for images in 'dataset\\malaria\\resized_images_by_classes'...\n",
            "\n",
            "Successfully created a dataset object!\n",
            "Total number of images found and loaded: 80111\n",
            "Number of classes: 7\n",
            "Classes found: ['difficult', 'gametocyte', 'leukocyte', 'red_blood_cell', 'ring', 'schizont', 'trophozoite']\n",
            "\n",
            "--- Verifying a single sample from the dataset ---\n",
            "Type of the image data: <class 'torch.Tensor'>\n",
            "Shape of the image tensor: torch.Size([3, 128, 128])\n",
            "Label index: 0\n"
          ]
        }
      ],
      "source": [
        "class CustomCellDataset(Dataset):\n",
        "    def __init__(self, image_data, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            image_data (list): A list of tuples (image_path, class_name).\n",
        "            transform (callable, optional): Optional transform to be applied on a sample.\n",
        "        \"\"\"\n",
        "        self.image_data = image_data\n",
        "        self.transform = transform\n",
        "\n",
        "        # Create a mapping from class name (string) to class index (integer)\n",
        "        self.classes = sorted(list(set(item[1] for item in image_data)))\n",
        "        self.class_to_idx = {class_name: i for i, class_name in enumerate(self.classes)}\n",
        "        self.idx_to_class = {i: class_name for class_name, i in self.class_to_idx.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        # This returns the total number of images in the dataset.\n",
        "        return len(self.image_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # This method loads and returns a single sample from the dataset at the given index.\n",
        "\n",
        "        # Get the path and string label for the given index\n",
        "        image_path, class_name = self.image_data[idx]\n",
        "\n",
        "        # Load the image using Pillow\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "        # Get the integer label from the class name using our mapping\n",
        "        label = self.class_to_idx[class_name]\n",
        "\n",
        "        # Apply transforms if they exist\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# --- Step 3: Define Your Transformations ---\n",
        "# This is where you define the on-the-fly augmentation and normalization.\n",
        "# IMPORTANT: Since your images are already resized, we DO NOT need transforms.Resize() here.\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1),\n",
        "    transforms.ToTensor(), # Converts the image to a PyTorch Tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # Normalizes the tensor\n",
        "])\n",
        "\n",
        "# --- Step 4: Put It All Together and Create Your Dataset Object ---\n",
        "if __name__ == '__main__':\n",
        "    # Define the path to your folder of RESIZED images.\n",
        "    # Assuming 'root_path' is defined, e.g., root_path = '/content/drive/MyDrive/fyp/malaria_dataset'\n",
        "    try:\n",
        "        RESIZED_DATA_DIR = os.path.join(root_path, 'resized_images_by_classes')\n",
        "    except NameError:\n",
        "        RESIZED_DATA_DIR = 'resized_images_by_classes' # Fallback if root_path isn't defined\n",
        "\n",
        "    # 1. Get the list of all image paths and labels\n",
        "    all_images = get_image_paths_and_labels(RESIZED_DATA_DIR)\n",
        "\n",
        "    if all_images:\n",
        "        # 2. Create an instance of your custom dataset\n",
        "        # This is the dataset object you will use for everything that follows.\n",
        "        my_dataset = CustomCellDataset(\n",
        "            image_data=all_images,\n",
        "            transform=train_transform\n",
        "        )\n",
        "\n",
        "        print(f\"\\nSuccessfully created a dataset object!\")\n",
        "        print(f\"Total number of images found and loaded: {len(my_dataset)}\")\n",
        "        print(f\"Number of classes: {len(my_dataset.classes)}\")\n",
        "        print(f\"Classes found: {my_dataset.classes}\")\n",
        "\n",
        "        # --- (Optional) How to Verify It Worked ---\n",
        "        print(\"\\n--- Verifying a single sample from the dataset ---\")\n",
        "\n",
        "        # Let's get the first image and its label from the dataset\n",
        "        image_tensor, label_index = my_dataset[0]\n",
        "\n",
        "        print(f\"Type of the image data: {type(image_tensor)}\")\n",
        "        print(f\"Shape of the image tensor: {image_tensor.shape}\")\n",
        "        print(f\"Label index: {label_index}\")\n",
        "\n",
        "        # You can see the shape is [3, 224, 224] (Channels, Height, Width), which confirms\n",
        "        # the ToTensor() and resizing (from your previous step) worked correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "nhkQZuAxZk9O"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Class Counts for Weight Calculation ---\n",
            "category\n",
            "difficult           441\n",
            "gametocyte          144\n",
            "leukocyte           103\n",
            "red blood cell    77420\n",
            "ring                353\n",
            "schizont            179\n",
            "trophozoite        1473\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- Calculated Weight per Class ---\n",
            "tensor([2.2676e-03, 6.9444e-03, 9.7087e-03, 1.2917e-05, 2.8329e-03, 5.5866e-03,\n",
            "        6.7889e-04])\n",
            "\n",
            "WeightedRandomSampler created successfully.\n",
            "\n",
            "✅ Final Training DataLoader is ready!\n"
          ]
        }
      ],
      "source": [
        "# Get the class counts, sorted by class name to ensure consistent order\n",
        "counts = train_class_counts.sort_index()\n",
        "print(\"--- Class Counts for Weight Calculation ---\")\n",
        "print(counts)\n",
        "\n",
        "# Calculate a weight for each class (less frequent class = higher weight)\n",
        "class_weights = 1. / torch.tensor(counts.values, dtype=torch.float)\n",
        "print(\"\\n--- Calculated Weight per Class ---\")\n",
        "print(class_weights)\n",
        "\n",
        "# Create a list containing the weight for EVERY sample in the dataset\n",
        "# This is the crucial step that assigns the correct weight to each of your 80,000 images\n",
        "sample_weights = [\n",
        "    class_weights[my_dataset.class_to_idx[label]]\n",
        "    for _, label in my_dataset.image_data\n",
        "]\n",
        "\n",
        "# --- Step 2: Create the Sampler ---\n",
        "# The sampler will use these weights to perform balanced sampling\n",
        "sampler = WeightedRandomSampler(\n",
        "    weights=torch.DoubleTensor(sample_weights),\n",
        "    num_samples=len(my_dataset),\n",
        "    replacement=True\n",
        ")\n",
        "print(\"\\nWeightedRandomSampler created successfully.\")\n",
        "\n",
        "# --- Step 3: Create the Final Training DataLoader ---\n",
        "BATCH_SIZE = 64  # You can tune this based on your GPU memory\n",
        "NUM_WORKERS = 4  # Use multiple workers to load data in parallel\n",
        "\n",
        "# IMPORTANT: When using a 'sampler', you must NOT use 'shuffle=True'.\n",
        "# The sampler handles the randomization in a balanced way.\n",
        "train_loader = DataLoader(\n",
        "    dataset=my_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    sampler=sampler,\n",
        "    num_workers=NUM_WORKERS\n",
        ")\n",
        "\n",
        "print(\"\\n✅ Final Training DataLoader is ready!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hSOjWQISZuJn"
      },
      "outputs": [],
      "source": [
        "# Get one batch of data from new train_loader\n",
        "images, labels = next(iter(train_loader))\n",
        "\n",
        "# Print the shape of the batch\n",
        "print(f\"\\n--- Verifying one batch from train_loader ---\")\n",
        "print(f\"Shape of the images tensor batch: {images.shape}\") # Should be [64, 3, 224, 224]\n",
        "print(f\"Shape of the labels tensor batch: {labels.shape}\")   # Should be [64]\n",
        "\n",
        "# Count the occurrences of each class IN THIS BATCH\n",
        "# This will show the effect of the sampler!\n",
        "print(f\"\\nClass distribution within this single batch:\")\n",
        "print(torch.bincount(labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DNlA5BhZvge"
      },
      "source": [
        "## Data training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "5VaKtbSVH_nC"
      },
      "outputs": [],
      "source": [
        "# Paths to your JSON files and image directory\n",
        "train_json_path = os.path.join(root_path, 'training.json')\n",
        "test_json_path = os.path.join(root_path, 'test.json')\n",
        "\n",
        "image_root_dir = root_path\n",
        "image_path = os.path.join(image_root_dir, 'images')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpxciS-Kjkw2",
        "outputId": "dc1c41bc-8c07-4de0-c187-d2d37af6c8e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scanning for images in 'dataset\\malaria\\resized_images_by_classes'...\n",
            "\n",
            "Successfully created a dataset object!\n",
            "Total number of images found and loaded: 80111\n",
            "Number of classes: 7\n",
            "Classes found: ['difficult', 'gametocyte', 'leukocyte', 'red_blood_cell', 'ring', 'schizont', 'trophozoite']\n",
            "\n",
            "--- Verifying a single sample from the dataset ---\n",
            "Type of the image data: <class 'torch.Tensor'>\n",
            "Shape of the image tensor: torch.Size([3, 128, 128])\n",
            "Label index: 0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# --- Step 1: Helper Function to Get All Image Paths ---\n",
        "# This function scans your directory and creates a list of (image_path, class_name) tuples.\n",
        "\n",
        "def get_image_paths_and_labels(base_folder):\n",
        "    \"\"\"\n",
        "    Walks through subdirectories and collects image paths and their corresponding\n",
        "    class labels derived from the folder names.\n",
        "    \"\"\"\n",
        "    if not os.path.isdir(base_folder):\n",
        "        print(f\"Error: Directory not found at '{base_folder}'\")\n",
        "        return None\n",
        "\n",
        "    image_data = []\n",
        "    print(f\"Scanning for images in '{base_folder}'...\")\n",
        "\n",
        "    # os.walk will traverse the directory tree\n",
        "    for root, _, files in os.walk(base_folder):\n",
        "        class_name = os.path.basename(root)\n",
        "\n",
        "        # Skip the top-level directory itself, only process class subfolders\n",
        "        if class_name == os.path.basename(base_folder):\n",
        "            continue\n",
        "\n",
        "        for filename in files:\n",
        "            if filename.lower().endswith(('.png', '.jpg', 'jpeg')):\n",
        "                image_path = os.path.join(root, filename)\n",
        "                image_data.append((image_path, class_name))\n",
        "\n",
        "    return image_data\n",
        "\n",
        "# --- Step 2: The Custom PyTorch Dataset Class ---\n",
        "# This class takes the list from Step 1 and knows how to load and transform an image\n",
        "# when the DataLoader asks for it.\n",
        "\n",
        "class CustomCellDataset(Dataset):\n",
        "    def __init__(self, image_data, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            image_data (list): A list of tuples (image_path, class_name).\n",
        "            transform (callable, optional): Optional transform to be applied on a sample.\n",
        "        \"\"\"\n",
        "        self.image_data = image_data\n",
        "        self.transform = transform\n",
        "\n",
        "        # Create a mapping from class name (string) to class index (integer)\n",
        "        self.classes = sorted(list(set(item[1] for item in image_data)))\n",
        "        self.class_to_idx = {class_name: i for i, class_name in enumerate(self.classes)}\n",
        "        self.idx_to_class = {i: class_name for class_name, i in self.class_to_idx.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        # This returns the total number of images in the dataset.\n",
        "        return len(self.image_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # This method loads and returns a single sample from the dataset at the given index.\n",
        "\n",
        "        # Get the path and string label for the given index\n",
        "        image_path, class_name = self.image_data[idx]\n",
        "\n",
        "        # Load the image using Pillow\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "        # Get the integer label from the class name using our mapping\n",
        "        label = self.class_to_idx[class_name]\n",
        "\n",
        "        # Apply transforms if they exist\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# --- Step 3: Define Your Transformations ---\n",
        "# This is where you define the on-the-fly augmentation and normalization.\n",
        "# IMPORTANT: Since your images are already resized, we DO NOT need transforms.Resize() here.\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    # No transforms.Resize() needed!\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1),\n",
        "    transforms.ToTensor(), # Converts the image to a PyTorch Tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # Normalizes the tensor\n",
        "])\n",
        "\n",
        "# --- Step 4: Put It All Together and Create Your Dataset Object ---\n",
        "if __name__ == '__main__':\n",
        "    # Define the path to your folder of RESIZED images.\n",
        "    # Assuming 'root_path' is defined, e.g., root_path = '/content/drive/MyDrive/fyp/malaria_dataset'\n",
        "    try:\n",
        "        RESIZED_DATA_DIR = os.path.join(root_path, 'resized_images_by_classes')\n",
        "    except NameError:\n",
        "        RESIZED_DATA_DIR = 'resized_images_by_classes' # Fallback if root_path isn't defined\n",
        "\n",
        "    # 1. Get the list of all image paths and labels\n",
        "    all_images = get_image_paths_and_labels(RESIZED_DATA_DIR)\n",
        "\n",
        "    if all_images:\n",
        "        # 2. Create an instance of your custom dataset\n",
        "        # This is the dataset object you will use for everything that follows.\n",
        "        my_dataset = CustomCellDataset(\n",
        "            image_data=all_images,\n",
        "            transform=train_transform\n",
        "        )\n",
        "\n",
        "        print(f\"\\nSuccessfully created a dataset object!\")\n",
        "        print(f\"Total number of images found and loaded: {len(my_dataset)}\")\n",
        "        print(f\"Number of classes: {len(my_dataset.classes)}\")\n",
        "        print(f\"Classes found: {my_dataset.classes}\")\n",
        "\n",
        "        # --- (Optional) How to Verify It Worked ---\n",
        "        print(\"\\n--- Verifying a single sample from the dataset ---\")\n",
        "        # Let's get the first image and its label from the dataset\n",
        "        image_tensor, label_index = my_dataset[0]\n",
        "\n",
        "        print(f\"Type of the image data: {type(image_tensor)}\")\n",
        "        print(f\"Shape of the image tensor: {image_tensor.shape}\")\n",
        "        print(f\"Label index: {label_index}\")\n",
        "\n",
        "        # You can see the shape is [3, 224, 224] (Channels, Height, Width), which confirms\n",
        "        # the ToTensor() and resizing (from your previous step) worked correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jI-vLpeI3gy",
        "outputId": "0268200d-baec-4091-f952-8da9e6bb0bb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "category\n",
            "red blood cell    77420\n",
            "trophozoite        1473\n",
            "difficult           441\n",
            "ring                353\n",
            "schizont            179\n",
            "gametocyte          144\n",
            "leukocyte           103\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Loading training data metadata\n",
        "with open(train_json_path, 'r') as f:\n",
        "    training_data = json.load(f)\n",
        "\n",
        "# Extract all object categories into a list\n",
        "all_categories = []\n",
        "for item in training_data:\n",
        "    for obj in item['objects']:\n",
        "        all_categories.append(obj['category'])\n",
        "\n",
        "# Create a pandas DataFrame for easy counting and plotting\n",
        "df = pd.DataFrame(all_categories, columns=['category'])\n",
        "\n",
        "train_class_counts = df['category'].value_counts()\n",
        "print(train_class_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRuPor8yGD8H",
        "outputId": "3d3703bb-9e09-4734-97b7-5bda320baf48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Class Counts for Weight Calculation ---\n",
            "category\n",
            "difficult           441\n",
            "gametocyte          144\n",
            "leukocyte           103\n",
            "red blood cell    77420\n",
            "ring                353\n",
            "schizont            179\n",
            "trophozoite        1473\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- Calculated Weight per Class ---\n",
            "tensor([2.2676e-03, 6.9444e-03, 9.7087e-03, 1.2917e-05, 2.8329e-03, 5.5866e-03,\n",
            "        6.7889e-04])\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'WeightedRandomSampler' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     15\u001b[39m sample_weights = [\n\u001b[32m     16\u001b[39m     class_weights[my_dataset.class_to_idx[label]]\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m _, label \u001b[38;5;129;01min\u001b[39;00m my_dataset.image_data\n\u001b[32m     18\u001b[39m ]\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# --- Step 2: Create the Sampler ---\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# The sampler will use these weights to perform balanced sampling\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m sampler = \u001b[43mWeightedRandomSampler\u001b[49m(\n\u001b[32m     23\u001b[39m     weights=torch.DoubleTensor(sample_weights),\n\u001b[32m     24\u001b[39m     num_samples=\u001b[38;5;28mlen\u001b[39m(my_dataset),\n\u001b[32m     25\u001b[39m     replacement=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     26\u001b[39m )\n\u001b[32m     27\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mWeightedRandomSampler created successfully.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# --- Step 3: Create the Final Training DataLoader ---\u001b[39;00m\n",
            "\u001b[31mNameError\u001b[39m: name 'WeightedRandomSampler' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "# --- Step 1: Calculate Weights for the Sampler ---\n",
        "\n",
        "# Get the class counts, sorted by class name to ensure consistent order\n",
        "counts = train_class_counts.sort_index()\n",
        "print(\"--- Class Counts for Weight Calculation ---\")\n",
        "print(counts)\n",
        "\n",
        "# Calculate a weight for each class (less frequent class = higher weight)\n",
        "class_weights = 1. / torch.tensor(counts.values, dtype=torch.float)\n",
        "print(\"\\n--- Calculated Weight per Class ---\")\n",
        "print(class_weights)\n",
        "\n",
        "# Create a list containing the weight for EVERY sample in the dataset\n",
        "# This is the crucial step that assigns the correct weight to each of your 80,000 images\n",
        "sample_weights = [\n",
        "    class_weights[my_dataset.class_to_idx[label]]\n",
        "    for _, label in my_dataset.image_data\n",
        "]\n",
        "\n",
        "# --- Step 2: Create the Sampler ---\n",
        "# The sampler will use these weights to perform balanced sampling\n",
        "sampler = WeightedRandomSampler(\n",
        "    weights=torch.DoubleTensor(sample_weights),\n",
        "    num_samples=len(my_dataset),\n",
        "    replacement=True\n",
        ")\n",
        "print(\"\\nWeightedRandomSampler created successfully.\")\n",
        "\n",
        "# --- Step 3: Create the Final Training DataLoader ---\n",
        "BATCH_SIZE = 64  # You can tune this based on your GPU memory\n",
        "NUM_WORKERS = 4  # Use multiple workers to load data in parallel\n",
        "\n",
        "# IMPORTANT: When using a 'sampler', you must NOT use 'shuffle=True'.\n",
        "# The sampler handles the randomization in a balanced way.\n",
        "train_loader = DataLoader(\n",
        "    dataset=my_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    sampler=sampler,\n",
        "    num_workers=NUM_WORKERS\n",
        ")\n",
        "\n",
        "print(\"\\n✅ Final Training DataLoader is ready!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIUqV_SjGGzY",
        "outputId": "86a4cdd4-dbfb-4206-8405-b9a4e5eb5660"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Verifying one batch from train_loader ---\n",
            "Shape of the images tensor batch: torch.Size([64, 3, 224, 224])\n",
            "Shape of the labels tensor batch: torch.Size([64])\n",
            "\n",
            "Class distribution within this single batch:\n",
            "tensor([ 4,  6,  7,  0,  1, 46])\n"
          ]
        }
      ],
      "source": [
        "# Get one batch of data from your new train_loader\n",
        "images, labels = next(iter(train_loader))\n",
        "\n",
        "# Print the shape of the batch\n",
        "print(f\"\\n--- Verifying one batch from train_loader ---\")\n",
        "print(f\"Shape of the images tensor batch: {images.shape}\") # Should be [64, 3, 224, 224]\n",
        "print(f\"Shape of the labels tensor batch: {labels.shape}\")   # Should be [64]\n",
        "\n",
        "# Count the occurrences of each class IN THIS BATCH\n",
        "# This will show the effect of the sampler!\n",
        "print(f\"\\nClass distribution within this single batch:\")\n",
        "print(torch.bincount(labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LMIwKW7GG28",
        "outputId": "874553ef-1e60-484e-a60a-564e95898e26"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:03<00:00, 28.3MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Starting feature extraction on 2693 images ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 43/43 [19:37<00:00, 27.38s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Feature Extraction Complete ---\n",
            "Feature matrix shape (X): (2693, 2048)\n",
            "Labels vector shape (y): (2693,)\n",
            "\n",
            "--- Data split into 2019 training and 674 testing samples ---\n",
            "\n",
            "--- Training Support Vector Machine ---\n",
            "--- Evaluating SVM ---\n",
            "SVM Accuracy: 0.6751\n",
            "\n",
            "SVM Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   difficult       0.38      0.45      0.41       110\n",
            "  gametocyte       0.41      0.36      0.38        36\n",
            "   leukocyte       1.00      0.88      0.94        26\n",
            "        ring       0.78      0.82      0.80        88\n",
            "    schizont       0.42      0.33      0.37        45\n",
            " trophozoite       0.78      0.77      0.77       369\n",
            "\n",
            "    accuracy                           0.68       674\n",
            "   macro avg       0.63      0.60      0.61       674\n",
            "weighted avg       0.68      0.68      0.68       674\n",
            "\n",
            "\n",
            "--- Training Random Forest ---\n",
            "--- Evaluating Random Forest ---\n",
            "Random Forest Accuracy: 0.6395\n",
            "\n",
            "Random Forest Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   difficult       0.29      0.21      0.24       110\n",
            "  gametocyte       0.50      0.03      0.05        36\n",
            "   leukocyte       1.00      0.62      0.76        26\n",
            "        ring       0.88      0.56      0.68        88\n",
            "    schizont       0.33      0.04      0.08        45\n",
            " trophozoite       0.66      0.92      0.77       369\n",
            "\n",
            "    accuracy                           0.64       674\n",
            "   macro avg       0.61      0.40      0.43       674\n",
            "weighted avg       0.61      0.64      0.59       674\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "# --- 1. SETUP FOR FEATURE EXTRACTION ---\n",
        "\n",
        "# Use a DataLoader to process images in batches.\n",
        "# IMPORTANT: shuffle must be False to keep features and labels aligned.\n",
        "feature_loader = DataLoader(\n",
        "    dataset=my_dataset,\n",
        "    batch_size=64,\n",
        "    shuffle=False, # Must be False!\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "# Load a pre-trained ResNet-50 model\n",
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "# Modify the model by removing its final classification layer.\n",
        "# This turns it into a feature extractor.\n",
        "feature_extractor = nn.Sequential(*list(model.children())[:-1])\n",
        "\n",
        "# Set up device (GPU or CPU) and put the model in evaluation mode\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "feature_extractor.to(device)\n",
        "feature_extractor.eval()\n",
        "\n",
        "\n",
        "# --- 2. EXTRACT FEATURES FROM ALL IMAGES ---\n",
        "\n",
        "print(f\"--- Starting feature extraction on {len(my_dataset)} images ---\")\n",
        "all_features = []\n",
        "all_labels = []\n",
        "\n",
        "# Loop through all data in the DataLoader\n",
        "with torch.no_grad(): # Deactivates gradient calculation for speed\n",
        "    for images, labels in tqdm(feature_loader):\n",
        "        images = images.to(device)\n",
        "\n",
        "        # Get the features from the model\n",
        "        features = feature_extractor(images)\n",
        "\n",
        "        # Flatten the features to a 1D vector per image\n",
        "        features = features.view(features.size(0), -1)\n",
        "\n",
        "        # Store the features and labels\n",
        "        all_features.append(features.cpu())\n",
        "        all_labels.append(labels.cpu())\n",
        "\n",
        "# Combine all batches into single tensors, then convert to NumPy arrays\n",
        "X = torch.cat(all_features).numpy()\n",
        "y = torch.cat(all_labels).numpy()\n",
        "\n",
        "print(\"\\n--- Feature Extraction Complete ---\")\n",
        "print(f\"Feature matrix shape (X): {X.shape}\")\n",
        "print(f\"Labels vector shape (y): {y.shape}\")\n",
        "\n",
        "\n",
        "# --- 3. TRAIN AND EVALUATE TRADITIONAL ML MODELS ---\n",
        "\n",
        "# Split the extracted features into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.25, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"\\n--- Data split into {len(X_train)} training and {len(X_test)} testing samples ---\")\n",
        "\n",
        "\n",
        "# --- A. Support Vector Machine (SVM) ---\n",
        "print(\"\\n--- Training Support Vector Machine ---\")\n",
        "# Using probability=True can be useful but is slower\n",
        "svm_model = SVC(kernel='linear', C=1.0, random_state=42)\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "print(\"--- Evaluating SVM ---\")\n",
        "y_pred_svm = svm_model.predict(X_test)\n",
        "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
        "print(f\"SVM Accuracy: {accuracy_svm:.4f}\")\n",
        "print(\"\\nSVM Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_svm, target_names=my_dataset.classes))\n",
        "\n",
        "\n",
        "# --- B. Random Forest ---\n",
        "print(\"\\n--- Training Random Forest ---\")\n",
        "# n_jobs=-1 uses all available CPU cores to speed up training\n",
        "rf_model = RandomForestClassifier(n_estimators=150, random_state=42, n_jobs=-1)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "print(\"--- Evaluating Random Forest ---\")\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "print(f\"Random Forest Accuracy: {accuracy_rf:.4f}\")\n",
        "print(\"\\nRandom Forest Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_rf, target_names=my_dataset.classes))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5WLFAQRj_G5"
      },
      "source": [
        "## SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZeGCtaZj9cO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5XFPWJTkA1i"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqGGSuHkj9ee"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNpGrjDqkD0N"
      },
      "source": [
        "## XG Boost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTYf5EoJj9gh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wF959tXIkSXN"
      },
      "source": [
        "## Cross Validation & Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPBGbA3hj9ik"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "726iyHvRkg7N"
      },
      "source": [
        "Use k-fold CV (e.g., k=5)\n",
        "\n",
        "\n",
        "Compute:\n",
        "\n",
        "\n",
        "Accuracy\n",
        "\n",
        "\n",
        "Precision\n",
        "\n",
        "\n",
        "Recall\n",
        "\n",
        "\n",
        "F1-score\n",
        "\n",
        "\n",
        "ROC-AUC\n",
        "\n",
        "\n",
        "Generate confusion matrix and ROC curves.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8fsyEqnj9ki"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gnnru2rMj9md"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGNoZanvj9pY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "fyp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
